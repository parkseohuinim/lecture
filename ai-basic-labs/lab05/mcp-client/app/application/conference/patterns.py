"""
LangGraph Multi-Agent Patterns
- Sequential (íŒŒì´í”„ë¼ì¸)
- Planner-Executor (ê³„íš-ì‹¤í–‰)
- Role-based Collaboration (ì—­í•  ë¶„ë‹´)
- Hierarchical (ìƒí•˜ êµ¬ì¡°)
- Debate / Critic (í† ë¡ Â·ê²€ì¦)
- Swarm / Market-based (êµ°ì§‘Â·ê²½ìŸ)
"""
from typing import TypedDict, Annotated, Sequence, List, Dict, Any, Optional, Callable, Awaitable
from typing_extensions import TypedDict as TypedDictExt
import operator
import json
import logging
from langgraph.graph import StateGraph, END
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage

logger = logging.getLogger(__name__)


# ============================================================================
# ìŠ¤íŠ¸ë¦¬ë° ì½œë°± íƒ€ì… ì •ì˜
# ============================================================================
StreamCallback = Callable[[str, str], Awaitable[None]]  # (node_name, token) -> None


# ============================================================================
# State Definitions
# ============================================================================

class AgentState(TypedDict):
    """ê¸°ë³¸ ì—ì´ì „íŠ¸ ìƒíƒœ"""
    topic: str
    messages: Annotated[List[BaseMessage], operator.add]
    current_step: str
    results: Dict[str, Any]


class RoleBasedState(TypedDict):
    """Role-based íŒ¨í„´ ì „ìš© ìƒíƒœ (ë³‘ë ¬ ì‹¤í–‰ ì§€ì›)"""
    topic: str
    # ê° ì—­í• ë³„ ë…ë¦½ì ì¸ í•„ë“œ (ë³‘ë ¬ ì—…ë°ì´íŠ¸ ê°€ëŠ¥)
    pm_opinion: Optional[str]
    dev_opinion: Optional[str]
    design_opinion: Optional[str]
    qa_opinion: Optional[str]
    final_decision: Optional[str]
    # ë©”ì‹œì§€ëŠ” ìë™ í•©ì³ì§
    messages: Annotated[List[BaseMessage], operator.add]


class HierarchicalState(TypedDict):
    """Hierarchical íŒ¨í„´ ì „ìš© ìƒíƒœ (ë³‘ë ¬ ì‹¤í–‰ ì§€ì›)"""
    topic: str
    assignments: Optional[Dict[str, str]]
    # ê° ì›Œì»¤ë³„ ë…ë¦½ì ì¸ í•„ë“œ
    worker1_result: Optional[str]
    worker2_result: Optional[str]
    worker3_result: Optional[str]
    final_report: Optional[str]
    messages: Annotated[List[BaseMessage], operator.add]


class SwarmAgentState(TypedDict):
    """Swarm íŒ¨í„´ ì „ìš© ìƒíƒœ (Market-based ê²½ìŸ ì§€ì›)"""
    task: str
    # ì„ íƒ ê¸°ì¤€ (ëª©ì  í•¨ìˆ˜)
    selection_criteria: Optional[Dict[str, Any]]
    # ê° ì—ì´ì „íŠ¸ë³„ ë…ë¦½ì ì¸ í•„ë“œ (ì…ì°° ì •ë³´ í¬í•¨)
    agent1_proposal: Optional[Dict[str, Any]]
    agent2_proposal: Optional[Dict[str, Any]]
    agent3_proposal: Optional[Dict[str, Any]]
    agent4_proposal: Optional[Dict[str, Any]]
    agent5_proposal: Optional[Dict[str, Any]]
    winner: Optional[Dict[str, Any]]
    selection_reasoning: Optional[str]  # ì„ íƒ ê·¼ê±°
    messages: Annotated[List[BaseMessage], operator.add]


class PlannerState(TypedDict):
    """Planner-Executor ìƒíƒœ"""
    task: str
    plan: List[Dict[str, str]]
    current_step: int
    executions: List[Dict[str, Any]]
    messages: Annotated[Sequence[BaseMessage], operator.add]
    final_result: str


class DebateState(TypedDict):
    """Debate ìƒíƒœ"""
    topic: str
    proposal: str
    critique: str
    round_num: int
    max_rounds: int
    conversation: List[Dict[str, str]]
    messages: Annotated[Sequence[BaseMessage], operator.add]
    final_decision: str


class SwarmState(TypedDict):
    """Swarm ìƒíƒœ"""
    task: str
    agent_proposals: List[Dict[str, Any]]
    num_agents: int
    messages: Annotated[Sequence[BaseMessage], operator.add]
    winner: Dict[str, Any]


class ReflectionState(TypedDict):
    """Reflection / Self-Refinement íŒ¨í„´ ìƒíƒœ"""
    task: str
    current_draft: Optional[str]
    reflection: Optional[str]
    revision_history: List[Dict[str, str]]
    iteration: int
    max_iterations: int
    quality_score: Optional[float]
    previous_score: Optional[float]  # ì´ì „ ì ìˆ˜ (ê°œì„ í­ ê³„ì‚°ìš©)
    quality_threshold: float
    improvement_threshold: float  # ìµœì†Œ ê°œì„ í­ (ì´í•˜ë©´ ì¢…ë£Œ)
    termination_reason: Optional[str]  # ì¢…ë£Œ ì‚¬ìœ 
    messages: Annotated[List[BaseMessage], operator.add]
    final_output: Optional[str]


class RoutingState(TypedDict):
    """Routing / Orchestration íŒ¨í„´ ìƒíƒœ (ë‹¤ì¤‘ í›„ë³´ ê²½ìŸ ì§€ì›)"""
    user_request: str
    routing_decision: Optional[Dict[str, Any]]
    selected_agent: Optional[str]
    confidence_score: Optional[float]
    # âœ¨ ë‹¤ì¤‘ í›„ë³´ ê²½ìŸì„ ìœ„í•œ í•„ë“œ
    candidate_scores: Optional[Dict[str, Dict[str, Any]]]  # ëª¨ë“  í›„ë³´ì˜ ì ìˆ˜ ë° í‰ê°€
    elimination_reasons: Optional[Dict[str, str]]  # íƒˆë½ ì‚¬ìœ 
    agent_result: Optional[str]
    routing_log: List[Dict[str, Any]]
    messages: Annotated[List[BaseMessage], operator.add]
    final_response: Optional[str]


class HITLState(TypedDict):
    """Human-in-the-Loop íŒ¨í„´ ìƒíƒœ (ì‹¤ì œ ì‚¬ëŒ ê°œì… ì§€ì›)"""
    task: str
    agent_proposal: Optional[str]
    # âœ¨ ì›Œí¬í”Œë¡œìš° ìƒíƒœ (ì‹¤ì œ ì‚¬ëŒ ê°œì… ìœ„í•œ ìƒíƒœ í™•ì¥)
    workflow_status: str  # "processing", "awaiting_human_input", "approved", "rejected", "revision_requested", "completed"
    awaiting_input: bool  # ì‚¬ëŒ ì…ë ¥ ëŒ€ê¸° ì¤‘ ì—¬ë¶€
    human_feedback: Optional[str]
    human_decision: Optional[str]  # "approve", "reject", "revision"
    revision_count: int
    max_revisions: int
    revision_history: List[Dict[str, Any]]  # ìˆ˜ì • ì´ë ¥
    messages: Annotated[List[BaseMessage], operator.add]
    final_output: Optional[str]


# ============================================================================
# 1ï¸âƒ£ Sequential (íŒŒì´í”„ë¼ì¸) Pattern
# ============================================================================

class SequentialPattern:
    """
    Sequential Pattern: A â†’ B â†’ C â†’ D
    ê° ì—ì´ì „íŠ¸ê°€ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ë˜ë©°, ì´ì „ ê²°ê³¼ë¥¼ ë‹¤ìŒ ì—ì´ì „íŠ¸ê°€ ë°›ì•„ ì²˜ë¦¬
    """
    
    def __init__(self, llm_service, stream_callback: Optional[StreamCallback] = None):
        self.llm_service = llm_service
        self.stream_callback = stream_callback
    
    def set_stream_callback(self, callback: Optional[StreamCallback]):
        """ìŠ¤íŠ¸ë¦¬ë° ì½œë°± ì„¤ì •"""
        self.stream_callback = callback
    
    async def _generate_with_streaming(self, prompt: str, node_name: str) -> str:
        """ìŠ¤íŠ¸ë¦¬ë° ì½œë°±ì´ ìˆìœ¼ë©´ í† í° ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë°, ì—†ìœ¼ë©´ ì¼ë°˜ ìƒì„±"""
        if self.stream_callback:
            # í† í° ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ
            content = ""
            async for token in self.llm_service.generate_response_stream(prompt):
                content += token
                await self.stream_callback(node_name, token)
            return content
        else:
            # ì¼ë°˜ ëª¨ë“œ
            return await self.llm_service.generate_response(prompt)
    
    async def agent_summarizer(self, state: AgentState) -> AgentState:
        """Agent 1: ìš”ì•½ ì „ë¬¸ê°€"""
        logger.info("ğŸ¤– [Agent 1: ìš”ì•½ ì „ë¬¸ê°€] ì‹œì‘")
        
        summary = await self._generate_with_streaming(
            f"""[ì—­í• : ìš”ì•½ ì „ë¬¸ê°€]
            ë‹¤ìŒ ì£¼ì œë¥¼ ê°„ë‹¨ëª…ë£Œí•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”:
            
            ì£¼ì œ: {state['topic']}
            
            ìš”ì•½ì€ 3-5ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ë§Œ ì¶”ì¶œí•˜ì„¸ìš”.""",
            "summarizer"
        )
        
        state['results']['summary'] = summary
        state['messages'].append(AIMessage(content=f"[ìš”ì•½ ì „ë¬¸ê°€]\n{summary}"))
        state['current_step'] = 'analyzer'
        
        logger.info(f"âœ… [Agent 1] ì™„ë£Œ: {len(summary)} characters")
        return state
    
    async def agent_analyzer(self, state: AgentState) -> AgentState:
        """Agent 2: ë¶„ì„ ì „ë¬¸ê°€"""
        logger.info("ğŸ¤– [Agent 2: ë¶„ì„ ì „ë¬¸ê°€] ì‹œì‘")
        
        summary = state['results'].get('summary', '')
        
        analysis = await self._generate_with_streaming(
            f"""[ì—­í• : ë¶„ì„ ì „ë¬¸ê°€]
            ë‹¤ìŒ ìš”ì•½ì„ ë°”íƒ•ìœ¼ë¡œ ì‹¬ì¸µ ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:
            
            ìš”ì•½:
            {summary}
            
            ë¶„ì„ í•­ëª©:
            1. í•µì‹¬ ê°œë…
            2. ì¥ë‹¨ì 
            3. ì‹¤ë¬´ ì ìš© ê°€ëŠ¥ì„±""",
            "analyzer"
        )
        
        state['results']['analysis'] = analysis
        state['messages'].append(AIMessage(content=f"[ë¶„ì„ ì „ë¬¸ê°€]\n{analysis}"))
        state['current_step'] = 'validator'
        
        logger.info(f"âœ… [Agent 2] ì™„ë£Œ: {len(analysis)} characters")
        return state
    
    async def agent_validator(self, state: AgentState) -> AgentState:
        """Agent 3: ê²€ì¦ ì „ë¬¸ê°€"""
        logger.info("ğŸ¤– [Agent 3: ê²€ì¦ ì „ë¬¸ê°€] ì‹œì‘")
        
        analysis = state['results'].get('analysis', '')
        
        validation = await self._generate_with_streaming(
            f"""[ì—­í• : ê²€ì¦ ì „ë¬¸ê°€]
            ë‹¤ìŒ ë¶„ì„ ë‚´ìš©ì„ ê²€ì¦í•˜ê³  ìµœì¢… ì˜ê²¬ì„ ì œì‹œí•´ì£¼ì„¸ìš”:
            
            ë¶„ì„ ë‚´ìš©:
            {analysis}
            
            ê²€ì¦ í•­ëª©:
            1. ë…¼ë¦¬ì  ì¼ê´€ì„±
            2. ëˆ„ë½ëœ ì¤‘ìš” ì‚¬í•­
            3. ìµœì¢… ì¶”ì²œ ì‚¬í•­""",
            "validator"
        )
        
        state['results']['validation'] = validation
        state['messages'].append(AIMessage(content=f"[ê²€ì¦ ì „ë¬¸ê°€]\n{validation}"))
        state['current_step'] = 'end'
        
        logger.info(f"âœ… [Agent 3] ì™„ë£Œ: {len(validation)} characters")
        return state
    
    def create_graph(self) -> StateGraph:
        """Sequential ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„±"""
        workflow = StateGraph(AgentState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("summarizer", self.agent_summarizer)
        workflow.add_node("analyzer", self.agent_analyzer)
        workflow.add_node("validator", self.agent_validator)
        
        # ì—£ì§€ ì¶”ê°€ (ìˆœì°¨ ì‹¤í–‰)
        workflow.set_entry_point("summarizer")
        workflow.add_edge("summarizer", "analyzer")
        workflow.add_edge("analyzer", "validator")
        workflow.add_edge("validator", END)
        
        return workflow.compile()


# ============================================================================
# 2ï¸âƒ£ Planner-Executor Pattern
# ============================================================================

class PlannerExecutorPattern:
    """
    Planner-Executor Pattern: ê³„íš ìˆ˜ë¦½ â†’ ë‹¨ê³„ë³„ ì‹¤í–‰
    Plannerê°€ ì‘ì—…ì„ ì—¬ëŸ¬ ë‹¨ê³„ë¡œ ë‚˜ëˆ„ê³ , Executorê°€ ê° ë‹¨ê³„ë¥¼ ì‹¤í–‰
    """
    
    def __init__(self, llm_service, stream_callback: Optional[StreamCallback] = None):
        self.llm_service = llm_service
        self.stream_callback = stream_callback
    
    def set_stream_callback(self, callback: Optional[StreamCallback]):
        """ìŠ¤íŠ¸ë¦¬ë° ì½œë°± ì„¤ì •"""
        self.stream_callback = callback
    
    async def _generate_with_streaming(self, prompt: str, node_name: str) -> str:
        """ìŠ¤íŠ¸ë¦¬ë° ì½œë°±ì´ ìˆìœ¼ë©´ í† í° ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë°, ì—†ìœ¼ë©´ ì¼ë°˜ ìƒì„±"""
        if self.stream_callback:
            content = ""
            async for token in self.llm_service.generate_response_stream(prompt):
                content += token
                await self.stream_callback(node_name, token)
            return content
        else:
            return await self.llm_service.generate_response(prompt)
    
    async def planner_node(self, state: PlannerState) -> PlannerState:
        """Planner: ì‘ì—…ì„ ë‹¨ê³„ë³„ë¡œ ë¶„í•´"""
        logger.info("ğŸ“‹ [Planner] ì‘ì—… ë¶„ì„ ë° ê³„íš ìˆ˜ë¦½ ì¤‘...")
        
        plan_response = await self._generate_with_streaming(
            f"""[ì—­í• : Planner]
            ë‹¤ìŒ ì‘ì—…ì„ 3-5ê°œì˜ êµ¬ì²´ì ì¸ ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ ê³„íšì„ ìˆ˜ë¦½í•´ì£¼ì„¸ìš”.
            
            ì‘ì—…: {state['task']}
            
            ì¶œë ¥ í˜•ì‹ (JSON):
            {{
              "steps": [
                {{"step": 1, "action": "êµ¬ì²´ì ì¸ ì‘ì—… ë‚´ìš©"}},
                {{"step": 2, "action": "êµ¬ì²´ì ì¸ ì‘ì—… ë‚´ìš©"}},
                {{"step": 3, "action": "êµ¬ì²´ì ì¸ ì‘ì—… ë‚´ìš©"}}
              ]
            }}
            
            JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.""",
            "planner"
        )
        
        # JSON íŒŒì‹±
        try:
            # JSON ì¶”ì¶œ (```json ... ``` ì œê±°)
            if '```json' in plan_response:
                plan_response = plan_response.split('```json')[1].split('```')[0].strip()
            elif '```' in plan_response:
                plan_response = plan_response.split('```')[1].split('```')[0].strip()
            
            plan_data = json.loads(plan_response)
            state['plan'] = plan_data.get('steps', [])
            state['current_step'] = 0
            
            logger.info(f"âœ… [Planner] ê³„íš ìˆ˜ë¦½ ì™„ë£Œ: {len(state['plan'])}ê°œ ë‹¨ê³„")
            state['messages'].append(AIMessage(content=f"[Planner]\nê³„íš ìˆ˜ë¦½ ì™„ë£Œ: {len(state['plan'])}ê°œ ë‹¨ê³„"))
            
        except Exception as e:
            logger.error(f"âŒ [Planner] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ ê³„íš
            state['plan'] = [
                {"step": 1, "action": "ì‘ì—… ë¶„ì„"},
                {"step": 2, "action": "ì‹¤í–‰"},
                {"step": 3, "action": "ê²€ì¦"}
            ]
            state['messages'].append(AIMessage(content=f"[Planner]\nê¸°ë³¸ ê³„íš ì‚¬ìš©"))
        
        return state
    
    async def executor_node(self, state: PlannerState) -> PlannerState:
        """Executor: í˜„ì¬ ë‹¨ê³„ ì‹¤í–‰"""
        current_idx = state['current_step']
        
        if current_idx >= len(state['plan']):
            state['current_step'] = -1  # ì™„ë£Œ í‘œì‹œ
            return state
        
        step = state['plan'][current_idx]
        logger.info(f"âš™ï¸ [Executor] Step {step['step']} ì‹¤í–‰ ì¤‘...")
        
        execution_result = await self._generate_with_streaming(
            f"""[ì—­í• : Executor]
            ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:
            
            ì‘ì—…: {step['action']}
            ì „ì²´ ì»¨í…ìŠ¤íŠ¸: {state['task']}
            
            êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ì œì‹œí•˜ì„¸ìš”.""",
            "executor"
        )
        
        state['executions'].append({
            "step": step['step'],
            "action": step['action'],
            "result": execution_result
        })
        
        state['messages'].append(AIMessage(content=f"[Executor - Step {step['step']}]\n{execution_result}"))
        state['current_step'] += 1
        
        logger.info(f"âœ… [Executor] Step {step['step']} ì™„ë£Œ")
        return state
    
    def should_continue(self, state: PlannerState) -> str:
        """ë‹¤ìŒ ë‹¨ê³„ ê²°ì •"""
        if state['current_step'] < 0 or state['current_step'] >= len(state['plan']):
            return "summarize"
        return "execute"
    
    async def summarizer_node(self, state: PlannerState) -> PlannerState:
        """ìµœì¢… ìš”ì•½"""
        logger.info("ğŸ“Š [Summarizer] ìµœì¢… ìš”ì•½ ì¤‘...")
        
        all_executions = "\n\n".join([
            f"Step {ex['step']}: {ex['action']}\nê²°ê³¼: {ex['result']}"
            for ex in state['executions']
        ])
        
        final_summary = await self._generate_with_streaming(
            f"""[ì—­í• : Summarizer]
            ë‹¤ìŒ ëª¨ë“  ì‹¤í–‰ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:
            
            ì›ë˜ ì‘ì—…: {state['task']}
            
            ì‹¤í–‰ ê²°ê³¼:
            {all_executions}
            
            ìµœì¢… ë³´ê³ ì„œì—ëŠ” ë‹¤ìŒì„ í¬í•¨í•˜ì„¸ìš”:
            1. ì£¼ìš” ë‹¬ì„± ì‚¬í•­
            2. í•µì‹¬ ì¸ì‚¬ì´íŠ¸
            3. ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ""",
            "summarizer_node"
        )
        
        state['final_result'] = final_summary
        state['messages'].append(AIMessage(content=f"[ìµœì¢… ë³´ê³ ì„œ]\n{final_summary}"))
        
        logger.info("âœ… [Summarizer] ì™„ë£Œ")
        return state
    
    def create_graph(self) -> StateGraph:
        """Planner-Executor ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„±"""
        workflow = StateGraph(PlannerState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("planner", self.planner_node)
        workflow.add_node("executor", self.executor_node)
        workflow.add_node("summarizer", self.summarizer_node)
        
        # ì—£ì§€ ì¶”ê°€
        workflow.set_entry_point("planner")
        workflow.add_edge("planner", "executor")
        
        # ì¡°ê±´ë¶€ ì—£ì§€: executor í›„ ê³„ì† ì‹¤í–‰í• ì§€ ê²°ì •
        workflow.add_conditional_edges(
            "executor",
            self.should_continue,
            {
                "execute": "executor",  # ë‹¤ìŒ ë‹¨ê³„ ì‹¤í–‰
                "summarize": "summarizer"  # ì™„ë£Œ í›„ ìš”ì•½
            }
        )
        
        workflow.add_edge("summarizer", END)
        
        return workflow.compile()


# ============================================================================
# 3ï¸âƒ£ Role-based Collaboration Pattern
# ============================================================================

class RoleBasedPattern:
    """
    Role-based Collaboration Pattern: ì—¬ëŸ¬ ì—­í• ì˜ ì—ì´ì „íŠ¸ê°€ **ë³‘ë ¬**ë¡œ ì˜ê²¬ ì œì‹œ
    PM, Developer, Designer, QAê°€ ê°ì ê´€ì ì—ì„œ **ë™ì‹œì—** ì˜ê²¬ â†’ Leaderê°€ í†µí•©
    
    âœ¨ í•µì‹¬: ë³‘ë ¬ ì‹¤í–‰ìœ¼ë¡œ ì‹œê°„ ì ˆì•½, ë…ë¦½ì ì¸ ê´€ì  ë³´ì¥
    """
    
    def __init__(self, llm_service, stream_callback: Optional[StreamCallback] = None):
        self.llm_service = llm_service
        self.stream_callback = stream_callback
        self.roles = ["PM", "Developer", "Designer", "QA"]
    
    def set_stream_callback(self, callback: Optional[StreamCallback]):
        """ìŠ¤íŠ¸ë¦¬ë° ì½œë°± ì„¤ì •"""
        self.stream_callback = callback
    
    async def _generate_with_streaming(self, prompt: str, node_name: str) -> str:
        """ìŠ¤íŠ¸ë¦¬ë° ì½œë°±ì´ ìˆìœ¼ë©´ í† í° ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë°, ì—†ìœ¼ë©´ ì¼ë°˜ ìƒì„±"""
        if self.stream_callback:
            content = ""
            async for token in self.llm_service.generate_response_stream(prompt):
                content += token
                await self.stream_callback(node_name, token)
            return content
        else:
            return await self.llm_service.generate_response(prompt)
    
    async def agent_pm(self, state: RoleBasedState) -> dict:
        """PM Agent - ë…ë¦½ì ì¸ í•„ë“œ ì—…ë°ì´íŠ¸"""
        logger.info("ğŸ‘” [PM] ì˜ê²¬ ì œì‹œ ì¤‘...")
        opinion = await self._generate_with_streaming(
            f"""[ì—­í• : Product Manager]
            ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ PM ê´€ì ì—ì„œ ì˜ê²¬ì„ ì œì‹œí•´ì£¼ì„¸ìš”:
            
            ì£¼ì œ: {state['topic']}
            
            ë‹¤ìŒ ì‚¬í•­ì„ í¬í•¨í•˜ì„¸ìš”:
            1. ë¹„ì¦ˆë‹ˆìŠ¤ ê°€ì¹˜
            2. ìš°ì„ ìˆœìœ„
            3. ë¦¬ìŠ¤í¬""",
            "pm"
        )
        logger.info("âœ… [PM] ì™„ë£Œ")
        return {
            'pm_opinion': opinion,
            'messages': [AIMessage(content=f"[PM]\n{opinion}")]
        }
    
    async def agent_developer(self, state: RoleBasedState) -> dict:
        """Developer Agent - ë…ë¦½ì ì¸ í•„ë“œ ì—…ë°ì´íŠ¸"""
        logger.info("ğŸ’» [Developer] ì˜ê²¬ ì œì‹œ ì¤‘...")
        opinion = await self._generate_with_streaming(
            f"""[ì—­í• : Developer]
            ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ê°œë°œì ê´€ì ì—ì„œ ì˜ê²¬ì„ ì œì‹œí•´ì£¼ì„¸ìš”:
            
            ì£¼ì œ: {state['topic']}
            
            ë‹¤ìŒ ì‚¬í•­ì„ í¬í•¨í•˜ì„¸ìš”:
            1. ê¸°ìˆ ì  íƒ€ë‹¹ì„±
            2. êµ¬í˜„ ë³µì¡ë„
            3. ìœ ì§€ë³´ìˆ˜ì„±""",
            "developer"
        )
        logger.info("âœ… [Developer] ì™„ë£Œ")
        return {
            'dev_opinion': opinion,
            'messages': [AIMessage(content=f"[Developer]\n{opinion}")]
        }
    
    async def agent_designer(self, state: RoleBasedState) -> dict:
        """Designer Agent - ë…ë¦½ì ì¸ í•„ë“œ ì—…ë°ì´íŠ¸"""
        logger.info("ğŸ¨ [Designer] ì˜ê²¬ ì œì‹œ ì¤‘...")
        opinion = await self._generate_with_streaming(
            f"""[ì—­í• : UX Designer]
            ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ë””ìì´ë„ˆ ê´€ì ì—ì„œ ì˜ê²¬ì„ ì œì‹œí•´ì£¼ì„¸ìš”:
            
            ì£¼ì œ: {state['topic']}
            
            ë‹¤ìŒ ì‚¬í•­ì„ í¬í•¨í•˜ì„¸ìš”:
            1. ì‚¬ìš©ì ê²½í—˜
            2. ì ‘ê·¼ì„±
            3. ë””ìì¸ ì¼ê´€ì„±""",
            "designer"
        )
        logger.info("âœ… [Designer] ì™„ë£Œ")
        return {
            'design_opinion': opinion,
            'messages': [AIMessage(content=f"[Designer]\n{opinion}")]
        }
    
    async def agent_qa(self, state: RoleBasedState) -> dict:
        """QA Agent - ë…ë¦½ì ì¸ í•„ë“œ ì—…ë°ì´íŠ¸"""
        logger.info("ğŸ” [QA] ì˜ê²¬ ì œì‹œ ì¤‘...")
        opinion = await self._generate_with_streaming(
            f"""[ì—­í• : QA Engineer]
            ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ QA ê´€ì ì—ì„œ ì˜ê²¬ì„ ì œì‹œí•´ì£¼ì„¸ìš”:
            
            ì£¼ì œ: {state['topic']}
            
            ë‹¤ìŒ ì‚¬í•­ì„ í¬í•¨í•˜ì„¸ìš”:
            1. í…ŒìŠ¤íŠ¸ ê°€ëŠ¥ì„±
            2. í’ˆì§ˆ ë¦¬ìŠ¤í¬
            3. ê²€ì¦ ì „ëµ""",
            "qa"
        )
        logger.info("âœ… [QA] ì™„ë£Œ")
        return {
            'qa_opinion': opinion,
            'messages': [AIMessage(content=f"[QA]\n{opinion}")]
        }
    
    async def agent_leader(self, state: RoleBasedState) -> dict:
        """Leader Agent: ëª¨ë“  ì˜ê²¬ í†µí•©"""
        logger.info("ğŸ‘¨â€ğŸ’¼ [Team Leader] ì˜ê²¬ í†µí•© ì¤‘...")
        
        all_opinions = "\n\n".join([
            f"[PMì˜ ì˜ê²¬]\n{state.get('pm_opinion', '(ì˜ê²¬ ì—†ìŒ)')}",
            f"[Developerì˜ ì˜ê²¬]\n{state.get('dev_opinion', '(ì˜ê²¬ ì—†ìŒ)')}",
            f"[Designerì˜ ì˜ê²¬]\n{state.get('design_opinion', '(ì˜ê²¬ ì—†ìŒ)')}",
            f"[QAì˜ ì˜ê²¬]\n{state.get('qa_opinion', '(ì˜ê²¬ ì—†ìŒ)')}"
        ])
        
        final_decision = await self._generate_with_streaming(
            f"""[ì—­í• : Team Leader]
            íŒ€ì›ë“¤ì˜ ì˜ê²¬ì„ ì¢…í•©í•˜ì—¬ ìµœì¢… ê²°ì •ì„ ë‚´ë ¤ì£¼ì„¸ìš”:
            
            ì£¼ì œ: {state['topic']}
            
            {all_opinions}
            
            ìµœì¢… ê²°ì •ì—ëŠ” ë‹¤ìŒì„ í¬í•¨í•˜ì„¸ìš”:
            1. í•µì‹¬ í•©ì˜ ì‚¬í•­
            2. íŠ¸ë ˆì´ë“œì˜¤í”„ ë¶„ì„
            3. ì‹¤í–‰ ê³„íš""",
            "leader"
        )
        
        logger.info("âœ… [Team Leader] ì™„ë£Œ")
        return {
            'final_decision': final_decision,
            'messages': [AIMessage(content=f"[Team Leader - ìµœì¢… ê²°ì •]\n{final_decision}")]
        }
    
    def create_graph(self) -> StateGraph:
        """Role-based ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„± - ë³‘ë ¬ ì‹¤í–‰!"""
        workflow = StateGraph(RoleBasedState)
        
        # ê° ì—­í•  ë…¸ë“œ ì¶”ê°€
        workflow.add_node("pm", self.agent_pm)
        workflow.add_node("developer", self.agent_developer)
        workflow.add_node("designer", self.agent_designer)
        workflow.add_node("qa", self.agent_qa)
        workflow.add_node("leader", self.agent_leader)
        
        # ë³‘ë ¬ ì‹¤í–‰: 4ê°œ ì—­í• ì´ ë™ì‹œì— ì‹œì‘
        workflow.set_entry_point("pm")
        workflow.set_entry_point("developer")
        workflow.set_entry_point("designer")
        workflow.set_entry_point("qa")
        
        # ëª¨ë“  ì—­í•  â†’ Leader (ëª¨ë‘ ì™„ë£Œë˜ë©´ Leader ì‹¤í–‰)
        workflow.add_edge("pm", "leader")
        workflow.add_edge("developer", "leader")
        workflow.add_edge("designer", "leader")
        workflow.add_edge("qa", "leader")
        
        workflow.add_edge("leader", END)
        
        logger.info("âœ… [Role-based] ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ - 4ê°œ ë…¸ë“œ ë³‘ë ¬ ì‹¤í–‰")
        return workflow.compile()


# ============================================================================
# 4ï¸âƒ£ Hierarchical Pattern
# ============================================================================

class HierarchicalPattern:
    """
    Hierarchical Pattern: Manager â†’ Workers (ë³‘ë ¬) â†’ Manager
    Managerê°€ ì‘ì—…ì„ ë¶„ë°°í•˜ê³ , Workerë“¤ì´ **ë³‘ë ¬** ì‹¤í–‰, Managerê°€ ê²°ê³¼ í†µí•©
    
    âœ¨ í•µì‹¬: ìƒí•˜ êµ¬ì¡°, ë³‘ë ¬ ì‘ì—… ë¶„ì‚°
    """
    
    def __init__(self, llm_service, stream_callback: Optional[StreamCallback] = None):
        self.llm_service = llm_service
        self.stream_callback = stream_callback
        self.num_workers = 3
    
    def set_stream_callback(self, callback: Optional[StreamCallback]):
        """ìŠ¤íŠ¸ë¦¬ë° ì½œë°± ì„¤ì •"""
        self.stream_callback = callback
    
    async def _generate_with_streaming(self, prompt: str, node_name: str) -> str:
        """ìŠ¤íŠ¸ë¦¬ë° ì½œë°±ì´ ìˆìœ¼ë©´ í† í° ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë°, ì—†ìœ¼ë©´ ì¼ë°˜ ìƒì„±"""
        if self.stream_callback:
            content = ""
            async for token in self.llm_service.generate_response_stream(prompt):
                content += token
                await self.stream_callback(node_name, token)
            return content
        else:
            return await self.llm_service.generate_response(prompt)
    
    async def manager_delegate(self, state: HierarchicalState) -> dict:
        """Manager: ì‘ì—… ë¶„ë°°"""
        logger.info("ğŸ‘¨â€ğŸ’¼ [Manager] ì‘ì—… ë¶„ë°° ì¤‘...")
        
        delegation_response = await self._generate_with_streaming(
            f"""[ì—­í• : Manager]
            ë‹¤ìŒ ì‘ì—…ì„ {self.num_workers}ëª…ì˜ ì›Œì»¤ì—ê²Œ ë¶„ë°°í•´ì£¼ì„¸ìš”.
            ê° ì›Œì»¤ì—ê²Œ êµ¬ì²´ì ì´ê³  ë…ë¦½ì ì¸ ì‘ì—…ì„ í• ë‹¹í•˜ì„¸ìš”.
            
            ì‘ì—…: {state['topic']}
            
            ì¶œë ¥ í˜•ì‹ (JSON):
            {{
              "worker1": "êµ¬ì²´ì ì¸ ì‘ì—… ì„¤ëª…",
              "worker2": "êµ¬ì²´ì ì¸ ì‘ì—… ì„¤ëª…",
              "worker3": "êµ¬ì²´ì ì¸ ì‘ì—… ì„¤ëª…"
            }}
            
            JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.""",
            "manager_delegate"
        )
        
        # JSON íŒŒì‹±
        try:
            if '```json' in delegation_response:
                delegation_response = delegation_response.split('```json')[1].split('```')[0].strip()
            elif '```' in delegation_response:
                delegation_response = delegation_response.split('```')[1].split('```')[0].strip()
            
            assignments = json.loads(delegation_response)
            logger.info(f"âœ… [Manager] ì‘ì—… ë¶„ë°° ì™„ë£Œ: {len(assignments)}ê°œ ì‘ì—…")
            
        except Exception as e:
            logger.error(f"âŒ [Manager] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            # í´ë°±
            assignments = {
                f"worker{i+1}": f"{state['topic']}ì˜ ì¼ë¶€ ì‘ì—… {i+1}"
                for i in range(self.num_workers)
            }
        
        return {
            'assignments': assignments,
            'messages': [AIMessage(content=f"[Manager - ì‘ì—… ë¶„ë°°]\n{json.dumps(assignments, ensure_ascii=False, indent=2)}")]
        }
    
    async def worker1_node(self, state: HierarchicalState) -> dict:
        """Worker 1 - ë…ë¦½ì ì¸ í•„ë“œ ì—…ë°ì´íŠ¸"""
        assignment = state.get('assignments', {}).get('worker1', "ì‘ì—… ì—†ìŒ")
        logger.info(f"ğŸ‘· [Worker 1] ì‘ì—… ìˆ˜í–‰ ì¤‘...")
        
        result = await self._generate_with_streaming(
            f"""[ì—­í• : Worker 1]
            ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:
            
            ì‘ì—…: {assignment}
            
            êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ì œì‹œí•˜ì„¸ìš”.""",
            "worker1"
        )
        
        logger.info(f"âœ… [Worker 1] ì™„ë£Œ")
        return {
            'worker1_result': result,
            'messages': [AIMessage(content=f"[Worker 1]\n{result}")]
        }
    
    async def worker2_node(self, state: HierarchicalState) -> dict:
        """Worker 2 - ë…ë¦½ì ì¸ í•„ë“œ ì—…ë°ì´íŠ¸"""
        assignment = state.get('assignments', {}).get('worker2', "ì‘ì—… ì—†ìŒ")
        logger.info(f"ğŸ‘· [Worker 2] ì‘ì—… ìˆ˜í–‰ ì¤‘...")
        
        result = await self._generate_with_streaming(
            f"""[ì—­í• : Worker 2]
            ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:
            
            ì‘ì—…: {assignment}
            
            êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ì œì‹œí•˜ì„¸ìš”.""",
            "worker2"
        )
        
        logger.info(f"âœ… [Worker 2] ì™„ë£Œ")
        return {
            'worker2_result': result,
            'messages': [AIMessage(content=f"[Worker 2]\n{result}")]
        }
    
    async def worker3_node(self, state: HierarchicalState) -> dict:
        """Worker 3 - ë…ë¦½ì ì¸ í•„ë“œ ì—…ë°ì´íŠ¸"""
        assignment = state.get('assignments', {}).get('worker3', "ì‘ì—… ì—†ìŒ")
        logger.info(f"ğŸ‘· [Worker 3] ì‘ì—… ìˆ˜í–‰ ì¤‘...")
        
        result = await self._generate_with_streaming(
            f"""[ì—­í• : Worker 3]
            ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:
            
            ì‘ì—…: {assignment}
            
            êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ì œì‹œí•˜ì„¸ìš”.""",
            "worker3"
        )
        
        logger.info(f"âœ… [Worker 3] ì™„ë£Œ")
        return {
            'worker3_result': result,
            'messages': [AIMessage(content=f"[Worker 3]\n{result}")]
        }
    
    async def manager_integrate(self, state: HierarchicalState) -> dict:
        """Manager: ê²°ê³¼ í†µí•©"""
        logger.info("ğŸ‘¨â€ğŸ’¼ [Manager] ê²°ê³¼ í†µí•© ì¤‘...")
        
        assignments = state.get('assignments', {})
        all_results = "\n\n".join([
            f"Worker 1:\nì‘ì—…: {assignments.get('worker1', '')}\nê²°ê³¼: {state.get('worker1_result', '')}",
            f"Worker 2:\nì‘ì—…: {assignments.get('worker2', '')}\nê²°ê³¼: {state.get('worker2_result', '')}",
            f"Worker 3:\nì‘ì—…: {assignments.get('worker3', '')}\nê²°ê³¼: {state.get('worker3_result', '')}"
        ])
        
        final_report = await self._generate_with_streaming(
            f"""[ì—­í• : Manager]
            ì›Œì»¤ë“¤ì˜ ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ìµœì¢… ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:
            
            ì›ë˜ ì‘ì—…: {state['topic']}
            
            ì›Œì»¤ ê²°ê³¼:
            {all_results}
            
            ìµœì¢… ë³´ê³ ì„œì—ëŠ” ë‹¤ìŒì„ í¬í•¨í•˜ì„¸ìš”:
            1. ì „ì²´ ìš”ì•½
            2. ì£¼ìš” ì„±ê³¼
            3. ê°œì„  ì œì•ˆ""",
            "manager_integrate"
        )
        
        logger.info("âœ… [Manager] ê²°ê³¼ í†µí•© ì™„ë£Œ")
        return {
            'final_report': final_report,
            'messages': [AIMessage(content=f"[Manager - ìµœì¢… ë³´ê³ ì„œ]\n{final_report}")]
        }
    
    def create_graph(self) -> StateGraph:
        """Hierarchical ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„± - ë³‘ë ¬ ì‹¤í–‰!"""
        workflow = StateGraph(HierarchicalState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("manager_delegate", self.manager_delegate)
        workflow.add_node("worker1", self.worker1_node)
        workflow.add_node("worker2", self.worker2_node)
        workflow.add_node("worker3", self.worker3_node)
        workflow.add_node("manager_integrate", self.manager_integrate)
        
        # Manager â†’ Workers (ë³‘ë ¬)
        workflow.set_entry_point("manager_delegate")
        workflow.add_edge("manager_delegate", "worker1")
        workflow.add_edge("manager_delegate", "worker2")
        workflow.add_edge("manager_delegate", "worker3")
        
        # Workers â†’ Manager (ëª¨ë‘ ì™„ë£Œë˜ë©´ Manager ì‹¤í–‰)
        workflow.add_edge("worker1", "manager_integrate")
        workflow.add_edge("worker2", "manager_integrate")
        workflow.add_edge("worker3", "manager_integrate")
        
        workflow.add_edge("manager_integrate", END)
        
        logger.info("âœ… [Hierarchical] ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ - 3ê°œ ì›Œì»¤ ë³‘ë ¬ ì‹¤í–‰")
        return workflow.compile()


# ============================================================================
# 5ï¸âƒ£ Debate / Critic Pattern
# ============================================================================

class DebatePattern:
    """
    Debate Pattern: Proposer â†” Critic ë°˜ë³µ â†’ Judge
    ì œì•ˆìì™€ ë¹„í‰ê°€ê°€ ì—¬ëŸ¬ ë¼ìš´ë“œ í† ë¡  í›„ ì‹¬íŒì´ ìµœì¢… ê²°ì •
    """
    
    def __init__(self, llm_service, max_rounds=3, stream_callback: Optional[StreamCallback] = None):
        self.llm_service = llm_service
        self.max_rounds = max_rounds
        self.stream_callback = stream_callback
    
    def set_stream_callback(self, callback: Optional[StreamCallback]):
        """ìŠ¤íŠ¸ë¦¬ë° ì½œë°± ì„¤ì •"""
        self.stream_callback = callback
    
    async def _generate_with_streaming(self, prompt: str, node_name: str) -> str:
        """ìŠ¤íŠ¸ë¦¬ë° ì½œë°±ì´ ìˆìœ¼ë©´ í† í° ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë°, ì—†ìœ¼ë©´ ì¼ë°˜ ìƒì„±"""
        if self.stream_callback:
            content = ""
            async for token in self.llm_service.generate_response_stream(prompt):
                content += token
                await self.stream_callback(node_name, token)
            return content
        else:
            return await self.llm_service.generate_response(prompt)
    
    async def proposer_initial(self, state: DebateState) -> DebateState:
        """Proposer: ì´ˆê¸° ì œì•ˆ"""
        logger.info("ğŸ’¡ [Proposer] ì´ˆê¸° ì œì•ˆ ì‘ì„± ì¤‘...")
        
        proposal = await self._generate_with_streaming(
            f"""[ì—­í• : Proposer]
            ë‹¤ìŒ ì£¼ì œì— ëŒ€í•œ ì œì•ˆì„ ì‘ì„±í•´ì£¼ì„¸ìš”:
            
            ì£¼ì œ: {state['topic']}
            
            ì œì•ˆì„œì— í¬í•¨í•  ë‚´ìš©:
            1. í•µì‹¬ ì•„ì´ë””ì–´
            2. ê¸°ëŒ€ íš¨ê³¼
            3. ì‹¤í–‰ ë°©ì•ˆ""",
            "proposer_initial"
        )
        
        state['proposal'] = proposal
        state['conversation'].append({"role": "proposer", "content": proposal})
        state['messages'].append(AIMessage(content=f"[Proposer - ì´ˆê¸° ì œì•ˆ]\n{proposal}"))
        state['round_num'] = 1
        
        logger.info("âœ… [Proposer] ì´ˆê¸° ì œì•ˆ ì™„ë£Œ")
        return state
    
    async def critic_node(self, state: DebateState) -> DebateState:
        """Critic: ë¹„íŒ"""
        logger.info(f"ğŸ” [Critic] Round {state['round_num']} ë¹„íŒ ì¤‘...")
        
        critique = await self._generate_with_streaming(
            f"""[ì—­í• : Critic]
            ë‹¤ìŒ ì œì•ˆì˜ ë¬¸ì œì ì„ ë‚ ì¹´ë¡­ê²Œ ì§€ì í•´ì£¼ì„¸ìš”:
            
            ì œì•ˆ:
            {state['proposal']}
            
            ë¹„íŒ í•­ëª©:
            1. ë…¼ë¦¬ì  ì˜¤ë¥˜
            2. ì‹¤í˜„ ê°€ëŠ¥ì„± ë¬¸ì œ
            3. ëˆ„ë½ëœ ì¤‘ìš” ì‚¬í•­""",
            "critic"
        )
        
        state['critique'] = critique
        state['conversation'].append({"role": "critic", "content": critique})
        state['messages'].append(AIMessage(content=f"[Critic - Round {state['round_num']}]\n{critique}"))
        
        logger.info(f"âœ… [Critic] Round {state['round_num']} ì™„ë£Œ")
        return state
    
    async def proposer_refine(self, state: DebateState) -> DebateState:
        """Proposer: ì œì•ˆ ê°œì„ """
        logger.info(f"ğŸ’¡ [Proposer] Round {state['round_num']} ì œì•ˆ ê°œì„  ì¤‘...")
        
        refined_proposal = await self._generate_with_streaming(
            f"""[ì—­í• : Proposer]
            ë¹„íŒì„ ë°˜ì˜í•˜ì—¬ ì œì•ˆì„ ê°œì„ í•´ì£¼ì„¸ìš”:
            
            ì›ë˜ ì œì•ˆ:
            {state['proposal']}
            
            ë°›ì€ ë¹„íŒ:
            {state['critique']}
            
            ê°œì„ ëœ ì œì•ˆì„ ì‘ì„±í•˜ì„¸ìš”.""",
            "proposer_refine"
        )
        
        state['proposal'] = refined_proposal
        state['conversation'].append({"role": "proposer_refined", "content": refined_proposal})
        state['messages'].append(AIMessage(content=f"[Proposer - ê°œì„ ì•ˆ Round {state['round_num']}]\n{refined_proposal}"))
        state['round_num'] += 1
        
        logger.info(f"âœ… [Proposer] Round {state['round_num']-1} ê°œì„  ì™„ë£Œ")
        return state
    
    def should_continue_debate(self, state: DebateState) -> str:
        """í† ë¡  ê³„ì† ì—¬ë¶€ ê²°ì •"""
        if state['round_num'] > state['max_rounds']:
            return "judge"
        return "critic"
    
    async def judge_node(self, state: DebateState) -> DebateState:
        """Judge: ìµœì¢… íŒê²°"""
        logger.info("âš–ï¸ [Judge] ìµœì¢… íŒê²° ì¤‘...")
        
        conversation_text = "\n\n".join([
            f"[{conv['role']}]\n{conv['content']}"
            for conv in state['conversation']
        ])
        
        final_decision = await self._generate_with_streaming(
            f"""[ì—­í• : Judge]
            ë‹¤ìŒ í† ë¡  ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… íŒê²°ì„ ë‚´ë ¤ì£¼ì„¸ìš”:
            
            ì£¼ì œ: {state['topic']}
            
            í† ë¡  ë‚´ìš©:
            {conversation_text}
            
            ìµœì¢… íŒê²°ì— í¬í•¨í•  ë‚´ìš©:
            1. í† ë¡ ì˜ ì£¼ìš” ìŸì 
            2. ê° ì¸¡ì˜ ê°•ì ê³¼ ì•½ì 
            3. ìµœì¢… ê²°ì • ë° ê·¼ê±°""",
            "judge"
        )
        
        state['final_decision'] = final_decision
        state['messages'].append(AIMessage(content=f"[Judge - ìµœì¢… íŒê²°]\n{final_decision}"))
        
        logger.info("âœ… [Judge] ìµœì¢… íŒê²° ì™„ë£Œ")
        return state
    
    def create_graph(self) -> StateGraph:
        """Debate ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„±"""
        workflow = StateGraph(DebateState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("proposer_initial", self.proposer_initial)
        workflow.add_node("critic", self.critic_node)
        workflow.add_node("proposer_refine", self.proposer_refine)
        workflow.add_node("judge", self.judge_node)
        
        # ì—£ì§€ ì¶”ê°€
        workflow.set_entry_point("proposer_initial")
        workflow.add_edge("proposer_initial", "critic")
        workflow.add_edge("critic", "proposer_refine")
        
        # ì¡°ê±´ë¶€ ì—£ì§€: ê³„ì† í† ë¡ í• ì§€ íŒê²°í• ì§€
        workflow.add_conditional_edges(
            "proposer_refine",
            self.should_continue_debate,
            {
                "critic": "critic",  # ë‹¤ìŒ ë¼ìš´ë“œ
                "judge": "judge"     # ì¢…ë£Œ
            }
        )
        
        workflow.add_edge("judge", END)
        
        return workflow.compile()


# ============================================================================
# 6ï¸âƒ£ Swarm / Market-based Pattern (ì§„ì •í•œ ì‹œì¥ ê²½ìŸ êµ¬í˜„)
# ============================================================================

class SwarmPattern:
    """
    Swarm / Market-based Pattern: ì´ì§ˆì  ì „ëµì„ ê°€ì§„ ì—ì´ì „íŠ¸ë“¤ì˜ ê²½ìŸ ì…ì°°
    
    âœ¨ í•µì‹¬ 3ìš”ì†Œ:
    1. ì´ì§ˆì  ì „ëµ: ê° ì—ì´ì „íŠ¸ê°€ ì™„ì „íˆ ë‹¤ë¥¸ ê´€ì /ì „ëµìœ¼ë¡œ ì ‘ê·¼
    2. ê²½ìŸ ì…ì°°: ìê¸°í‰ê°€ê°€ ì•„ë‹Œ ë¹„ìš©/ì‹œê°„/ìœ„í—˜ë„ ë“±ì˜ ì…ì°° ì •ë³´ ì œì¶œ
    3. ì‹œì¥ ë©”ì»¤ë‹ˆì¦˜: ëª©ì  í•¨ìˆ˜ ê¸°ë°˜ì˜ í•©ë¦¬ì  ì„ íƒ (ì¡°ê±´ ê¸°ë°˜ ìë™ ì„ íƒ)
    
    ğŸ† ì„ íƒ ê¸°ì¤€ ì˜ˆì‹œ:
    - "ìµœì†Œ ë¹„ìš©": cost ìµœì†Œí™”
    - "ìµœë‹¨ ì‹œê°„": duration ìµœì†Œí™”
    - "ê· í˜•": (cost * 0.3) + (duration * 0.3) + (risk * 0.2) + (1/performance * 0.2)
    """
    
    # 5ê°œ ì—ì´ì „íŠ¸ì˜ ê³ ìœ  ì „ëµ ì •ì˜
    AGENT_STRATEGIES = {
        1: {
            "name": "ë¹„ìš© ìµœì í™” ì „ë¬¸ê°€",
            "strategy": "cost_optimizer",
            "focus": "ìµœì†Œ ë¹„ìš©ìœ¼ë¡œ ë¬¸ì œ í•´ê²°",
            "approach": "ì˜¤í”ˆì†ŒìŠ¤, ìì²´ êµ¬ì¶•, ë¹„ìš© íš¨ìœ¨ì ì¸ ì†”ë£¨ì…˜ ì„ í˜¸"
        },
        2: {
            "name": "ì„±ëŠ¥ ìµœìš°ì„  ì „ë¬¸ê°€",
            "strategy": "performance_first",
            "focus": "ìµœê³  ì„±ëŠ¥ê³¼ í™•ì¥ì„± í™•ë³´",
            "approach": "í”„ë¦¬ë¯¸ì—„ ì†”ë£¨ì…˜, ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ë„êµ¬, ì„±ëŠ¥ ìµœì í™”"
        },
        3: {
            "name": "ë³´ì•ˆ ìµœìš°ì„  ì „ë¬¸ê°€",
            "strategy": "security_first",
            "focus": "ë³´ì•ˆê³¼ ì»´í”Œë¼ì´ì–¸ìŠ¤ ìµœìš°ì„ ",
            "approach": "ë³´ì•ˆ ì¸ì¦ ì†”ë£¨ì…˜, ê°ì‚¬ ì¶”ì , ì•”í˜¸í™”, ì ‘ê·¼ ì œì–´"
        },
        4: {
            "name": "ì†ë„ ìµœìš°ì„  ì „ë¬¸ê°€",
            "strategy": "speed_first",
            "focus": "ìµœë‹¨ ì‹œê°„ ë‚´ êµ¬í˜„ ì™„ë£Œ",
            "approach": "SaaS ì†”ë£¨ì…˜, í„´í‚¤ ì„œë¹„ìŠ¤, ë¹ ë¥¸ ë°°í¬, ê´€ë¦¬í˜• ì„œë¹„ìŠ¤"
        },
        5: {
            "name": "ìë™í™” ìµœìš°ì„  ì „ë¬¸ê°€",
            "strategy": "automation_first",
            "focus": "ìš´ì˜ ìë™í™”ì™€ ì¥ê¸° ìœ ì§€ë³´ìˆ˜ ìµœì†Œí™”",
            "approach": "IaC, GitOps, ìë™ ìŠ¤ì¼€ì¼ë§, ì…€í”„íë§ ì‹œìŠ¤í…œ"
        }
    }
    
    # ê¸°ë³¸ ì„ íƒ ê¸°ì¤€ (ëª©ì  í•¨ìˆ˜)
    DEFAULT_CRITERIA = {
        "priority": "balanced",  # balanced, cost, speed, performance, security
        "max_cost": 100,  # ìµœëŒ€ í—ˆìš© ë¹„ìš© (ë‹¨ìœ„: ë§Œì›/ì›”)
        "max_duration_weeks": 4,  # ìµœëŒ€ í—ˆìš© êµ¬ì¶• ê¸°ê°„ (ì£¼)
        "min_performance": 7,  # ìµœì†Œ ì„±ëŠ¥ ì ìˆ˜ (1-10)
        "weights": {
            "cost": 0.25,
            "duration": 0.25,
            "risk": 0.25,
            "performance": 0.25
        }
    }
    
    def __init__(self, llm_service, num_agents=5, stream_callback: Optional[StreamCallback] = None):
        self.llm_service = llm_service
        self.num_agents = min(num_agents, 5)
        self.stream_callback = stream_callback
    
    def set_stream_callback(self, callback: Optional[StreamCallback]):
        """ìŠ¤íŠ¸ë¦¬ë° ì½œë°± ì„¤ì •"""
        self.stream_callback = callback
    
    async def _generate_with_streaming(self, prompt: str, node_name: str) -> str:
        """ìŠ¤íŠ¸ë¦¬ë° ì½œë°±ì´ ìˆìœ¼ë©´ í† í° ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë°, ì—†ìœ¼ë©´ ì¼ë°˜ ìƒì„±"""
        if self.stream_callback:
            content = ""
            async for token in self.llm_service.generate_response_stream(prompt):
                content += token
                await self.stream_callback(node_name, token)
            return content
        else:
            return await self.llm_service.generate_response(prompt)
    
    async def agent1_node(self, state: SwarmAgentState) -> dict:
        """Agent 1: ë¹„ìš© ìµœì í™” ì „ë¬¸ê°€"""
        return await self._agent_logic(1, state)
    
    async def agent2_node(self, state: SwarmAgentState) -> dict:
        """Agent 2: ì„±ëŠ¥ ìµœìš°ì„  ì „ë¬¸ê°€"""
        return await self._agent_logic(2, state)
    
    async def agent3_node(self, state: SwarmAgentState) -> dict:
        """Agent 3: ë³´ì•ˆ ìµœìš°ì„  ì „ë¬¸ê°€"""
        return await self._agent_logic(3, state)
    
    async def agent4_node(self, state: SwarmAgentState) -> dict:
        """Agent 4: ì†ë„ ìµœìš°ì„  ì „ë¬¸ê°€"""
        return await self._agent_logic(4, state)
    
    async def agent5_node(self, state: SwarmAgentState) -> dict:
        """Agent 5: ìë™í™” ìµœìš°ì„  ì „ë¬¸ê°€"""
        return await self._agent_logic(5, state)
    
    async def _agent_logic(self, agent_id: int, state: SwarmAgentState) -> dict:
        """ì—ì´ì „íŠ¸ë³„ ê³ ìœ  ì „ëµ ê¸°ë°˜ ì†”ë£¨ì…˜ ì œì•ˆ ë° ì…ì°°"""
        strategy = self.AGENT_STRATEGIES[agent_id]
        logger.info(f"ğŸ [{strategy['name']}] ì…ì°° ì¤€ë¹„ ì¤‘...")
        
        prompt = f"""[ì—­í• : {strategy['name']}]
[ì „ëµ: {strategy['focus']}]
[ì ‘ê·¼ ë°©ì‹: {strategy['approach']}]

ë‹¹ì‹ ì€ **{strategy['strategy']}** ì „ëµì„ ê°€ì§„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ë¬¸ì œì— ëŒ€í•´ ë‹¹ì‹ ì˜ ì „ëµì— ë§ëŠ” ì†”ë£¨ì…˜ì„ ì œì•ˆí•˜ê³  ì…ì°° ì •ë³´ë¥¼ ì œì¶œí•˜ì„¸ìš”.

**ë¬¸ì œ:** {state['task']}

**ì¤‘ìš”:** ë‹¹ì‹ ì˜ ì „ëµ({strategy['focus']})ì— ì¶©ì‹¤í•œ ì†”ë£¨ì…˜ì„ ì œì•ˆí•˜ì„¸ìš”.
ë‹¤ë¥¸ ì „ëµê³¼ ì°¨ë³„í™”ëœ ê³ ìœ í•œ ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

**ì¶œë ¥ í˜•ì‹ (JSON):**
{{
    "solution_name": "ì†”ë£¨ì…˜ ì´ë¦„ (ì˜ˆ: Prometheus ê¸°ë°˜ ëª¨ë‹ˆí„°ë§)",
    "solution_description": "ì†”ë£¨ì…˜ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª… (3-5ë¬¸ì¥)",
    "key_components": ["í•µì‹¬ êµ¬ì„±ìš”ì†Œ 1", "í•µì‹¬ êµ¬ì„±ìš”ì†Œ 2", "í•µì‹¬ êµ¬ì„±ìš”ì†Œ 3"],
    "bid": {{
        "cost_monthly": 50,
        "duration_weeks": 2,
        "risk_level": 5,
        "performance_score": 8,
        "maintenance_effort": 6
    }},
    "trade_offs": {{
        "strengths": ["ì¥ì  1", "ì¥ì  2"],
        "weaknesses": ["ì•½ì  1", "ì•½ì  2"]
    }},
    "why_choose_me": "ì´ ì†”ë£¨ì…˜ì„ ì„ íƒí•´ì•¼ í•˜ëŠ” ì´ìœ  (1-2ë¬¸ì¥)"
}}

**ì…ì°° ì •ë³´ ê°€ì´ë“œ:**
- cost_monthly: ì›” ìš´ì˜ ë¹„ìš© (ë§Œì› ë‹¨ìœ„, 10~500 ë²”ìœ„)
- duration_weeks: êµ¬ì¶• ê¸°ê°„ (ì£¼ ë‹¨ìœ„, 1~12 ë²”ìœ„)
- risk_level: ìœ„í—˜ë„ (1=ë§¤ìš° ë‚®ìŒ ~ 10=ë§¤ìš° ë†’ìŒ)
- performance_score: ì„±ëŠ¥ ì ìˆ˜ (1=ë‚®ìŒ ~ 10=ìµœê³ )
- maintenance_effort: ìœ ì§€ë³´ìˆ˜ ë…¸ë ¥ (1=ê±°ì˜ ì—†ìŒ ~ 10=ë§¤ìš° ë§ìŒ)
            
            JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."""

        proposal_response = await self._generate_with_streaming(prompt, f"agent{agent_id}")
        
        # JSON íŒŒì‹±
        try:
            if '```json' in proposal_response:
                proposal_response = proposal_response.split('```json')[1].split('```')[0].strip()
            elif '```' in proposal_response:
                proposal_response = proposal_response.split('```')[1].split('```')[0].strip()
            
            proposal_data = json.loads(proposal_response)
            
            # ì…ì°° ì •ë³´ ì¶”ì¶œ
            bid = proposal_data.get("bid", {})
            
            agent_proposal = {
                "agent_id": agent_id,
                "strategy": strategy,
                "solution_name": proposal_data.get("solution_name", "ì œì•ˆ ì—†ìŒ"),
                "solution_description": proposal_data.get("solution_description", ""),
                "key_components": proposal_data.get("key_components", []),
                "bid": {
                    "cost_monthly": bid.get("cost_monthly", 100),
                    "duration_weeks": bid.get("duration_weeks", 4),
                    "risk_level": bid.get("risk_level", 5),
                    "performance_score": bid.get("performance_score", 5),
                    "maintenance_effort": bid.get("maintenance_effort", 5)
                },
                "trade_offs": proposal_data.get("trade_offs", {"strengths": [], "weaknesses": []}),
                "why_choose_me": proposal_data.get("why_choose_me", "")
            }
            
        except Exception as e:
            logger.error(f"âŒ [{strategy['name']}] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            agent_proposal = {
                "agent_id": agent_id,
                "strategy": strategy,
                "solution_name": "íŒŒì‹± ì‹¤íŒ¨",
                "solution_description": str(e),
                "key_components": [],
                "bid": {
                    "cost_monthly": 999,
                    "duration_weeks": 99,
                    "risk_level": 10,
                    "performance_score": 1,
                    "maintenance_effort": 10
                },
                "trade_offs": {"strengths": [], "weaknesses": ["íŒŒì‹± ì‹¤íŒ¨"]},
                "why_choose_me": ""
            }
        
        bid_info = agent_proposal["bid"]
        logger.info(f"âœ… [{strategy['name']}] ì…ì°° ì™„ë£Œ - ë¹„ìš©: {bid_info['cost_monthly']}ë§Œì›/ì›”, ê¸°ê°„: {bid_info['duration_weeks']}ì£¼")
        
        # ë©”ì‹œì§€ í¬ë§·íŒ…
        message_content = f"""**{strategy['name']}ì˜ ì…ì°°**

**ì†”ë£¨ì…˜: {agent_proposal['solution_name']}**
{agent_proposal['solution_description']}

**í•µì‹¬ êµ¬ì„±ìš”ì†Œ:**
{chr(10).join(['â€¢ ' + comp for comp in agent_proposal['key_components']])}

**ì…ì°° ì •ë³´:**
| í•­ëª© | ê°’ |
|------|-----|
| ì›” ë¹„ìš© | {bid_info['cost_monthly']}ë§Œì› |
| êµ¬ì¶• ê¸°ê°„ | {bid_info['duration_weeks']}ì£¼ |
| ìœ„í—˜ë„ | {bid_info['risk_level']}/10 |
| ì„±ëŠ¥ ì ìˆ˜ | {bid_info['performance_score']}/10 |
| ìœ ì§€ë³´ìˆ˜ ë…¸ë ¥ | {bid_info['maintenance_effort']}/10 |

**ì¥ì :** {', '.join(agent_proposal['trade_offs'].get('strengths', []))}
**ì•½ì :** {', '.join(agent_proposal['trade_offs'].get('weaknesses', []))}

**ì„ íƒ ì´ìœ :** {agent_proposal['why_choose_me']}"""
        
        return {
            f'agent{agent_id}_proposal': agent_proposal,
            'messages': [AIMessage(content=message_content)]
        }
    
    async def selector_node(self, state: SwarmAgentState) -> dict:
        """Selector: ëª©ì  í•¨ìˆ˜ ê¸°ë°˜ í•©ë¦¬ì  ì„ íƒ (Market-based)"""
        logger.info("ğŸ† [Market Selector] ì…ì°° í‰ê°€ ë° ì„ ì • ì¤‘...")
        
        # ì„ íƒ ê¸°ì¤€ ê°€ì ¸ì˜¤ê¸°
        criteria = state.get('selection_criteria') or self.DEFAULT_CRITERIA
        priority = criteria.get('priority', 'balanced')
        weights = criteria.get('weights', self.DEFAULT_CRITERIA['weights'])
        
        # ëª¨ë“  ì…ì°° ìˆ˜ì§‘
        all_proposals = []
        for i in range(1, 6):
            proposal = state.get(f'agent{i}_proposal')
            if proposal:
                all_proposals.append(proposal)
        
        if not all_proposals:
            logger.error("âŒ [Selector] ì…ì°° ì—†ìŒ")
            return {
                'winner': None,
                'selection_reasoning': "ì…ì°°ì´ ì—†ìŠµë‹ˆë‹¤.",
                'messages': [AIMessage(content="[Market Selector] ì…ì°°ì´ ì—†ìŠµë‹ˆë‹¤.")]
            }
        
        # ì…ì°° í‰ê°€ í…Œì´ë¸” ìƒì„±
        evaluation_table = []
        for p in all_proposals:
            bid = p['bid']
            strategy = p['strategy']
            
            # ì •ê·œí™” ì ìˆ˜ ê³„ì‚° (0-1 ë²”ìœ„, ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒìœ¼ë¡œ í†µì¼)
            # cost: ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ â†’ ê·¸ëŒ€ë¡œ
            # duration: ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ â†’ ê·¸ëŒ€ë¡œ
            # risk: ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ â†’ ê·¸ëŒ€ë¡œ
            # performance: ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ â†’ ì—­ìˆ˜ ì‚¬ìš©
            
            cost_score = bid['cost_monthly'] / 500  # 0-1 ì •ê·œí™” (500 ê¸°ì¤€)
            duration_score = bid['duration_weeks'] / 12  # 0-1 ì •ê·œí™” (12ì£¼ ê¸°ì¤€)
            risk_score = bid['risk_level'] / 10
            # ì„±ëŠ¥ì€ ë†’ì„ìˆ˜ë¡ ì¢‹ìœ¼ë¯€ë¡œ ì—­ì‚°
            perf_score = 1 - (bid['performance_score'] / 10)
            
            # ê°€ì¤‘ í•©ê³„ ì ìˆ˜ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            total_score = (
                weights['cost'] * cost_score +
                weights['duration'] * duration_score +
                weights['risk'] * risk_score +
                weights['performance'] * perf_score
            )
            
            evaluation_table.append({
                'proposal': p,
                'scores': {
                    'cost': cost_score,
                    'duration': duration_score,
                    'risk': risk_score,
                    'performance': perf_score
                },
                'total_score': total_score
            })
        
        # ìš°ì„ ìˆœìœ„ì— ë”°ë¥¸ ì •ë ¬
        if priority == 'cost':
            evaluation_table.sort(key=lambda x: x['scores']['cost'])
        elif priority == 'speed':
            evaluation_table.sort(key=lambda x: x['scores']['duration'])
        elif priority == 'performance':
            evaluation_table.sort(key=lambda x: x['scores']['performance'])
        elif priority == 'security':
            evaluation_table.sort(key=lambda x: x['scores']['risk'])
        else:  # balanced
            evaluation_table.sort(key=lambda x: x['total_score'])
        
        # ìµœì  ì œì•ˆ ì„ íƒ
        winner_eval = evaluation_table[0]
        winner = winner_eval['proposal']
        
        # ì„ íƒ ê·¼ê±° ìƒì„±
        priority_labels = {
            'balanced': 'ê· í˜• ì¡íŒ ì¢…í•© ì ìˆ˜',
            'cost': 'ìµœì†Œ ë¹„ìš©',
            'speed': 'ìµœë‹¨ êµ¬ì¶• ì‹œê°„',
            'performance': 'ìµœê³  ì„±ëŠ¥',
            'security': 'ìµœì € ìœ„í—˜ë„'
        }
        
        selection_reasoning = f"""**ëª©ì  í•¨ìˆ˜:** {priority_labels.get(priority, priority)}
**ê°€ì¤‘ì¹˜:** ë¹„ìš© {weights['cost']*100:.0f}%, ì‹œê°„ {weights['duration']*100:.0f}%, ìœ„í—˜ë„ {weights['risk']*100:.0f}%, ì„±ëŠ¥ {weights['performance']*100:.0f}%

ì„ ì • ê·¼ê±°: {winner['strategy']['name']}ì˜ ì†”ë£¨ì…˜ì´ ëª©ì  í•¨ìˆ˜ ê¸°ì¤€ ìµœì  ì ìˆ˜({winner_eval['total_score']:.3f})ë¥¼ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤."""
        
        # ì…ì°° ë¹„êµ í…Œì´ë¸” ë©”ì‹œì§€ ìƒì„±
        comparison_rows = []
        for i, ev in enumerate(evaluation_table):
            p = ev['proposal']
            bid = p['bid']
            rank = f"#{i+1}" if i < 3 else f" {i+1}"
            selected = "[ì„ ì •]" if i == 0 else ""
            comparison_rows.append(
                f"| {rank} {p['strategy']['name'][:12]} | {p['solution_name'][:15]} | {bid['cost_monthly']}ë§Œì› | {bid['duration_weeks']}ì£¼ | {bid['risk_level']}/10 | {bid['performance_score']}/10 | {ev['total_score']:.3f} | {selected} |"
            )
        
        comparison_table = "\n".join(comparison_rows)
        
        message_content = f"""**Market Selector - ì…ì°° í‰ê°€ ê²°ê³¼**

**ì„ íƒ ê¸°ì¤€ (ëª©ì  í•¨ìˆ˜)**
- ìš°ì„ ìˆœìœ„: **{priority_labels.get(priority, priority)}**
- ê°€ì¤‘ì¹˜: ë¹„ìš© {weights['cost']*100:.0f}% | ì‹œê°„ {weights['duration']*100:.0f}% | ìœ„í—˜ë„ {weights['risk']*100:.0f}% | ì„±ëŠ¥ {weights['performance']*100:.0f}%

**ì…ì°° ë¹„êµí‘œ** (ì ìˆ˜ê°€ ë‚®ì„ìˆ˜ë¡ ìœ ë¦¬)
| ìˆœìœ„ | ì†”ë£¨ì…˜ | ë¹„ìš© | ê¸°ê°„ | ìœ„í—˜ë„ | ì„±ëŠ¥ | ì¢…í•©ì ìˆ˜ | ì„ ì • |
|------|--------|------|------|--------|------|----------|------|
{comparison_table}

---

**ìµœì¢… ì„ ì •: {winner['strategy']['name']}**

**ì†”ë£¨ì…˜:** {winner['solution_name']}
{winner['solution_description']}

**ì…ì°° ì •ë³´:**
- ì›” ë¹„ìš©: {winner['bid']['cost_monthly']}ë§Œì›
- êµ¬ì¶• ê¸°ê°„: {winner['bid']['duration_weeks']}ì£¼
- ìœ„í—˜ë„: {winner['bid']['risk_level']}/10
- ì„±ëŠ¥: {winner['bid']['performance_score']}/10

**ì„ ì • ì‚¬ìœ :**
{selection_reasoning}

**ì°¨ì ì ëŒ€ì•ˆ:** {evaluation_table[1]['proposal']['strategy']['name']} - {evaluation_table[1]['proposal']['solution_name']} (ì ìˆ˜: {evaluation_table[1]['total_score']:.3f})"""
        
        logger.info(f"âœ… [Selector] {winner['strategy']['name']} ì„ ì •ë¨ (ì ìˆ˜: {winner_eval['total_score']:.3f})")
        
        return {
            'winner': winner,
            'selection_reasoning': selection_reasoning,
            'messages': [AIMessage(content=message_content)]
        }
    
    def create_graph(self) -> StateGraph:
        """Swarm ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„± - ë³‘ë ¬ ê²½ìŸ ì…ì°°!"""
        workflow = StateGraph(SwarmAgentState)
        
        # ì—ì´ì „íŠ¸ ë…¸ë“œ ì¶”ê°€ (ê°ì ë‹¤ë¥¸ ì „ëµ)
        workflow.add_node("agent1", self.agent1_node)  # ë¹„ìš© ìµœì í™”
        workflow.add_node("agent2", self.agent2_node)  # ì„±ëŠ¥ ìµœìš°ì„ 
        workflow.add_node("agent3", self.agent3_node)  # ë³´ì•ˆ ìµœìš°ì„ 
        workflow.add_node("agent4", self.agent4_node)  # ì†ë„ ìµœìš°ì„ 
        workflow.add_node("agent5", self.agent5_node)  # ìë™í™” ìµœìš°ì„ 
        workflow.add_node("selector", self.selector_node)
        
        # ë³‘ë ¬ ì‹¤í–‰: ëª¨ë“  ì—ì´ì „íŠ¸ ë™ì‹œ ì‹œì‘ (ê²½ìŸ ì…ì°°)
        workflow.set_entry_point("agent1")
        workflow.set_entry_point("agent2")
        workflow.set_entry_point("agent3")
        workflow.set_entry_point("agent4")
        workflow.set_entry_point("agent5")
        
        # ëª¨ë“  ì—ì´ì „íŠ¸ â†’ Market Selector
        workflow.add_edge("agent1", "selector")
        workflow.add_edge("agent2", "selector")
        workflow.add_edge("agent3", "selector")
        workflow.add_edge("agent4", "selector")
        workflow.add_edge("agent5", "selector")
        
        workflow.add_edge("selector", END)
        
        logger.info("âœ… [Swarm/Market] ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ - 5ê°œ ì „ëµ ì—ì´ì „íŠ¸ ê²½ìŸ ì…ì°°")
        return workflow.compile()


# ============================================================================
# 7ï¸âƒ£ Reflection / Self-Refinement Pattern
# ============================================================================

class ReflectionPattern:
    """
    Reflection / Self-Refinement Pattern: ìƒì„± â†’ í‰ê°€ â†’ ê°œì„ ì˜ ë°˜ë³µ ë£¨í”„
    
    âœ¨ í•µì‹¬ 3ë‹¨ê³„:
    1. Generator: ì´ˆì•ˆ ìƒì„± / í”¼ë“œë°± ë°˜ì˜ ìˆ˜ì •
    2. Reflector: í’ˆì§ˆ í‰ê°€ ë° ê°œì„ ì  ë„ì¶œ
    3. Finalizer: ìµœì¢… ê²°ê³¼ ì¶œë ¥
    
    âœ¨ ì¢…ë£Œ ì¡°ê±´ (3ê°€ì§€):
    1. í’ˆì§ˆ ê¸°ì¤€ ì¶©ì¡±: score >= threshold
    2. ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬: iteration >= max_iterations
    3. ê°œì„  ì •ì²´/í‡´í™” ê°ì§€: improvement < min_threshold ë˜ëŠ” score í•˜ë½
    
    âœ¨ Finalizer ì ìˆ˜ ì •ì±…:
    - ìµœì¢… ì ìˆ˜ = ë§ˆì§€ë§‰ Reflector ì ìˆ˜ (ë…¼ë¦¬ì  ì¼ê´€ì„± ë³´ì¥)
    - ë˜ëŠ” ì „ì²´ Reflector ì ìˆ˜ì˜ í‰ê· 
    """
    
    def __init__(self, llm_service, max_iterations=3, quality_threshold=8.0, improvement_threshold=0.3, stream_callback: Optional[StreamCallback] = None):
        self.llm_service = llm_service
        self.max_iterations = max_iterations
        self.quality_threshold = quality_threshold
        self.improvement_threshold = improvement_threshold  # ìµœì†Œ ê°œì„ í­
        self.stream_callback = stream_callback
    
    def set_stream_callback(self, callback: Optional[StreamCallback]):
        """ìŠ¤íŠ¸ë¦¬ë° ì½œë°± ì„¤ì •"""
        self.stream_callback = callback
    
    async def _generate_with_streaming(self, prompt: str, node_name: str) -> str:
        """ìŠ¤íŠ¸ë¦¬ë° ì½œë°±ì´ ìˆìœ¼ë©´ í† í° ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë°, ì—†ìœ¼ë©´ ì¼ë°˜ ìƒì„±"""
        if self.stream_callback:
            content = ""
            async for token in self.llm_service.generate_response_stream(prompt):
                content += token
                await self.stream_callback(node_name, token)
            return content
        else:
            return await self.llm_service.generate_response(prompt)
    
    async def generator_node(self, state: ReflectionState) -> dict:
        """Generator: ì´ˆì•ˆ ìƒì„± ë˜ëŠ” í”¼ë“œë°± ë°˜ì˜ ìˆ˜ì •"""
        iteration = state.get('iteration', 0)
        
        if iteration == 0:
            logger.info("ğŸ“ [Generator] ì´ˆì•ˆ ìƒì„± ì¤‘...")
            # âœ¨ ì˜ë„ì ìœ¼ë¡œ "ê°œì„  ì—¬ì§€ê°€ ìˆëŠ”" ê¸°ë³¸ ì´ˆì•ˆ ìƒì„±
            # â†’ ëª…í™•í•œ ê°œì„  ê³¡ì„ ì„ ë³´ì—¬ì£¼ê¸° ìœ„í•¨
            prompt = f"""ë‹¤ìŒ ì‘ì—…ì— ëŒ€í•œ **ê¸°ë³¸ ì´ˆì•ˆ**ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì‘ì—…: {state['task']}

**ì´ˆì•ˆ ì‘ì„± ê°€ì´ë“œë¼ì¸ (ì˜ë„ì ìœ¼ë¡œ ê°œì„  ì—¬ì§€ë¥¼ ë‚¨ê¹€):**
- í•µì‹¬ ê°œë…ê³¼ êµ¬ì¡°ë¥¼ ì¡ëŠ” ë° ì§‘ì¤‘
- êµ¬ì²´ì ì¸ ë„êµ¬ëª…ì´ë‚˜ ìˆ˜ì¹˜ëŠ” ì•„ì§ í¬í•¨í•˜ì§€ ì•ŠìŒ
- ì¶”ìƒì ì¸ ìˆ˜ì¤€ì˜ ì„¤ëª…ìœ¼ë¡œ ì‘ì„±
- ì‹¤ì œ ì‚¬ë¡€ë‚˜ ì •ëŸ‰ ë°ì´í„°ëŠ” ë‹¤ìŒ ê°œì„ ì—ì„œ ì¶”ê°€ ì˜ˆì •

ì´ ì´ˆì•ˆì€ ì´í›„ í‰ê°€ì™€ ê°œì„  ê³¼ì •ì„ í†µí•´ ì ì§„ì ìœ¼ë¡œ ë°œì „í•©ë‹ˆë‹¤.
ë¨¼ì € ê¸°ë³¸ ë¼ˆëŒ€ë¥¼ ì¡ëŠ” ì´ˆì•ˆì„ ì‘ì„±í•´ì£¼ì„¸ìš”."""
        else:
            logger.info(f"ğŸ“ [Generator] í”¼ë“œë°± ë°˜ì˜ ìˆ˜ì • ì¤‘ (Iteration {iteration + 1})...")
            # âœ¨ ê°œì„  ì‹œ êµ¬ì²´ì ì¸ ìš”ì†Œ ì¶”ê°€ ìœ ë„
            prompt = f"""ì´ì „ ì´ˆì•ˆê³¼ í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ **ëŒ€í­ ê°œì„ ëœ ë²„ì „**ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì›ë˜ ì‘ì—…: {state['task']}

ì´ì „ ì´ˆì•ˆ:
{state.get('current_draft', '')}

Reflector í”¼ë“œë°±:
{state.get('reflection', '')}

**ğŸ¯ ë°˜ë“œì‹œ ë‹¤ìŒ ê°œì„  ìš”ì†Œë¥¼ ì¶”ê°€í•˜ì„¸ìš” (ì ìˆ˜ ìƒìŠ¹ì„ ìœ„í•œ í•µì‹¬):**

1. **ì •ëŸ‰ ë°ì´í„° ì¶”ê°€**: êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, í†µê³„, KPI í¬í•¨
   ì˜ˆ: "ì¥ì•  ë³µêµ¬ ì‹œê°„ 42% ê°ì†Œ", "ë¹„ìš© 28% ì ˆê°"

2. **êµ¬ì²´ì  ë„êµ¬/ê¸°ìˆ ëª…**: ì‹¤ì œ ë„êµ¬ë‚˜ ê¸°ìˆ  ì´ë¦„ ëª…ì‹œ
   ì˜ˆ: "Prometheus + Grafana", "Datadog APM", "ELK Stack"

3. **ì‹¤ì œ ì‚¬ë¡€**: ê¸°ì—…ëª…ì„ í¬í•¨í•œ êµ¬ì²´ì  ì‚¬ë¡€
   ì˜ˆ: "NetflixëŠ” Chaos Engineeringìœ¼ë¡œ...", "Google SRE ì‚¬ë¡€ì—ì„œ..."

4. **ìš´ì˜/ì¡°ì§ ê´€ì **: SRE, ì˜¨ì½œ, SLA/SLO ë“± ìš´ì˜ ê´€ì  ì¶”ê°€

5. **ìµœì‹  íŠ¸ë Œë“œ**: AI/ML ê¸°ë°˜ ì˜ˆì¸¡, ìë™í™” ë“± ìµœì‹  ê¸°ìˆ  ì–¸ê¸‰

**ë°˜ë“œì‹œ í”¼ë“œë°±ì˜ ëª¨ë“  ê°œì„  ì œì•ˆì„ ì¶©ì‹¤íˆ ë°˜ì˜**í•˜ì„¸ìš”.
ì´ì „ë³´ë‹¤ í’ˆì§ˆ ì ìˆ˜ê°€ í™•ì‹¤íˆ ì˜¬ë¼ê°ˆ ìˆ˜ ìˆë„ë¡ êµ¬ì²´ì ì¸ ê°œì„ ì„ ì ìš©í•˜ì„¸ìš”."""
        
        draft = await self._generate_with_streaming(prompt, "generator")
        
        logger.info(f"âœ… [Generator] ì™„ë£Œ (Iteration {iteration + 1})")
        
        return {
            'current_draft': draft,
            'iteration': iteration + 1,
            'previous_score': state.get('quality_score'),  # ì´ì „ ì ìˆ˜ ì €ì¥
            'messages': [AIMessage(content=f"**[Generator - Iteration {iteration + 1}]**\n\n{draft}")]
        }
    
    async def reflector_node(self, state: ReflectionState) -> dict:
        """Reflector: í’ˆì§ˆ í‰ê°€ ë° ê°œì„ ì  ë„ì¶œ (ì—„ê²©í•œ í‰ê°€ ê¸°ì¤€)"""
        iteration = state.get('iteration', 1)
        previous_score = state.get('previous_score')
        
        logger.info(f"ğŸ” [Reflector] í’ˆì§ˆ í‰ê°€ ì¤‘ (Iteration {iteration})...")
        
        # ì´ì „ ì ìˆ˜ê°€ ìˆìœ¼ë©´ ì°¸ì¡°í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        comparison_note = ""
        if previous_score is not None:
            comparison_note = f"""

ğŸ“Š **ì´ì „ ë²„ì „ ì ìˆ˜:** {previous_score}ì 
- ê°œì„ ì´ **ì‹¤ì œë¡œ ë°˜ì˜**ë˜ì—ˆë‹¤ë©´ ì ìˆ˜ë¥¼ ì˜¬ë ¤ì£¼ì„¸ìš”.
- ê°œì„ ì´ ë¶€ì¡±í•˜ë©´ ë™ì¼í•˜ê±°ë‚˜ ë‚®ì€ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ì„¸ìš”."""
        
        # âœ¨ ì—„ê²©í•œ í‰ê°€ ê¸°ì¤€ìœ¼ë¡œ ì´ˆê¸° ì ìˆ˜ê°€ ë„ˆë¬´ ë†’ì§€ ì•Šë„ë¡
        prompt = f"""ë‹¤ìŒ ì´ˆì•ˆì„ **ì—„ê²©í•œ ê¸°ì¤€**ìœ¼ë¡œ í‰ê°€í•˜ê³  ê°œì„ ì ì„ ë„ì¶œí•´ì£¼ì„¸ìš”.

ì›ë˜ ì‘ì—…: {state['task']}

í˜„ì¬ ì´ˆì•ˆ (Iteration {iteration}):
{state['current_draft']}{comparison_note}

---

## ğŸ¯ í‰ê°€ ê¸°ì¤€ (ê° í•­ëª©ë‹¹ ìµœëŒ€ 2ì , ì´ 10ì )

| í•­ëª© | í‰ê°€ ê¸°ì¤€ | ë°°ì  |
|------|----------|------|
| 1. êµ¬ì¡°/ë…¼ë¦¬ | ëª…í™•í•œ êµ¬ì¡°ì™€ ë…¼ë¦¬ì  íë¦„ | 0-2ì  |
| 2. ì •ëŸ‰ ë°ì´í„° | êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, í†µê³„, KPI í¬í•¨ ì—¬ë¶€ | 0-2ì  |
| 3. êµ¬ì²´ì  ë„êµ¬/ê¸°ìˆ  | ì‹¤ì œ ë„êµ¬ëª…, ê¸°ìˆ  ìŠ¤íƒ ì–¸ê¸‰ ì—¬ë¶€ | 0-2ì  |
| 4. ì‹¤ì œ ì‚¬ë¡€ | ê¸°ì—…ëª… í¬í•¨ ì‹¤ì œ ì ìš© ì‚¬ë¡€ ì—¬ë¶€ | 0-2ì  |
| 5. ì „ë¬¸ì„±/ê¹Šì´ | ìš´ì˜ ê´€ì , ìµœì‹  íŠ¸ë Œë“œ, ì „ë¬¸ ìš©ì–´ í™œìš© | 0-2ì  |

**âš ï¸ ì ìˆ˜ ê°€ì´ë“œë¼ì¸:**
- **3-4ì **: ê¸°ë³¸ êµ¬ì¡°ë§Œ ìˆê³  êµ¬ì²´ì„± ë¶€ì¡± (ì´ˆì•ˆ ìˆ˜ì¤€)
- **5-6ì **: êµ¬ì¡° + ì¼ë¶€ êµ¬ì²´ì„± ìˆìŒ
- **7ì **: ì ˆë°˜ ì´ìƒì˜ ê¸°ì¤€ ì¶©ì¡±
- **8ì **: ëŒ€ë¶€ë¶„ì˜ ê¸°ì¤€ ì¶©ì¡±
- **9ì **: ëª¨ë“  ê¸°ì¤€ ì¶©ì¡± + ë†’ì€ ì™„ì„±ë„
- **10ì **: ì‹¤ë¬´ ë¬¸ì„œ ìˆ˜ì¤€ì˜ ì™„ë²½í•œ í’ˆì§ˆ

---

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ **ì •í™•í•˜ê²Œ** í‰ê°€í•´ì£¼ì„¸ìš”:

**í•­ëª©ë³„ í‰ê°€:**
- êµ¬ì¡°/ë…¼ë¦¬: ?/2ì 
- ì •ëŸ‰ ë°ì´í„°: ?/2ì 
- êµ¬ì²´ì  ë„êµ¬/ê¸°ìˆ : ?/2ì 
- ì‹¤ì œ ì‚¬ë¡€: ?/2ì 
- ì „ë¬¸ì„±/ê¹Šì´: ?/2ì 

**âš ï¸ ì¤‘ìš”: í’ˆì§ˆ ì ìˆ˜ = ìœ„ 5ê°œ í•­ëª© ì ìˆ˜ì˜ í•©ê³„ì…ë‹ˆë‹¤!**
**í’ˆì§ˆ ì ìˆ˜:** [í•­ëª©ë³„ ì ìˆ˜ë¥¼ ëª¨ë‘ ë”í•œ ê°’, ì˜ˆ: 2+0+1+0+1=4ì ì´ë©´ 4]

**ì˜ëœ ì :**
- (êµ¬ì²´ì ìœ¼ë¡œ ë‚˜ì—´)

**ê°œì„ ì´ í•„ìš”í•œ ì :**
- (êµ¬ì²´ì ìœ¼ë¡œ ë‚˜ì—´)

**êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆ:**
- (ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ì œì•ˆ - ì´ê²ƒì´ ì¶”ê°€ë˜ë©´ ì ìˆ˜ê°€ ì˜¬ë¼ê°ˆ ê²ƒ)

**ë°˜ë“œì‹œ** í•­ëª©ë³„ ì ìˆ˜ì˜ í•©ê³„ë¥¼ í’ˆì§ˆ ì ìˆ˜ë¡œ ê¸°ì…í•˜ì„¸ìš”. ë¶ˆì¼ì¹˜í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤!"""
        
        reflection = await self._generate_with_streaming(prompt, "reflector")
        
        import re
        
        # ë””ë²„ê¹…ì„ ìœ„í•´ ì‘ë‹µ ì•ë¶€ë¶„ ë¡œê¹…
        logger.info(f"ğŸ“ [Reflector] ì‘ë‹µ ì•ë¶€ë¶„: {reflection[:200]}...")
        
        # âœ¨ 1ë‹¨ê³„: í•­ëª©ë³„ ì ìˆ˜ íŒŒì‹± ë° í•©ì‚° (ê°€ì¥ ì •í™•í•œ ë°©ë²•)
        # íŒ¨í„´: "êµ¬ì¡°/ë…¼ë¦¬: 2/2ì " ë˜ëŠ” "- êµ¬ì¡°/ë…¼ë¦¬: 2/2ì "
        item_patterns = [
            r'êµ¬ì¡°\s*/?\s*ë…¼ë¦¬\s*:\s*(\d+(?:\.\d+)?)\s*/\s*2',      # êµ¬ì¡°/ë…¼ë¦¬: 2/2
            r'ì •ëŸ‰\s*ë°ì´í„°\s*:\s*(\d+(?:\.\d+)?)\s*/\s*2',         # ì •ëŸ‰ ë°ì´í„°: 1/2
            r'êµ¬ì²´ì \s*ë„êµ¬\s*/?\s*ê¸°ìˆ \s*:\s*(\d+(?:\.\d+)?)\s*/\s*2',  # êµ¬ì²´ì  ë„êµ¬/ê¸°ìˆ : 2/2
            r'ì‹¤ì œ\s*ì‚¬ë¡€\s*:\s*(\d+(?:\.\d+)?)\s*/\s*2',           # ì‹¤ì œ ì‚¬ë¡€: 0/2
            r'ì „ë¬¸ì„±\s*/?\s*ê¹Šì´\s*:\s*(\d+(?:\.\d+)?)\s*/\s*2',    # ì „ë¬¸ì„±/ê¹Šì´: 1/2
        ]
        
        item_scores = []
        for pattern in item_patterns:
            match = re.search(pattern, reflection, re.IGNORECASE)
            if match:
                item_scores.append(float(match.group(1)))
        
        # í•­ëª©ë³„ ì ìˆ˜ í•©ì‚° (5ê°œ í•­ëª© ëª¨ë‘ íŒŒì‹±ëœ ê²½ìš°)
        calculated_score = None
        if len(item_scores) == 5:
            calculated_score = sum(item_scores)
            logger.info(f"ğŸ“Š [Reflector] í•­ëª©ë³„ ì ìˆ˜ í•©ì‚°: {item_scores} = {calculated_score}")
        
        # âœ¨ 2ë‹¨ê³„: LLMì´ ëª…ì‹œí•œ í’ˆì§ˆ ì ìˆ˜ íŒŒì‹± (ë°±ì—…)
        llm_stated_score = None
        score_patterns = [
            r'\*\*í’ˆì§ˆ\s*ì ìˆ˜:\*\*\s*(\d+(?:\.\d+)?)',     # **í’ˆì§ˆ ì ìˆ˜:** 8
            r'\*\*í’ˆì§ˆ\s*ì ìˆ˜\*\*\s*:\s*(\d+(?:\.\d+)?)',  # **í’ˆì§ˆ ì ìˆ˜**: 8
            r'í’ˆì§ˆ\s*ì ìˆ˜\s*:\s*(\d+(?:\.\d+)?)',          # í’ˆì§ˆ ì ìˆ˜: 5
            r'í’ˆì§ˆ\s*ì ìˆ˜\s*:\s*\*\*(\d+(?:\.\d+)?)\*\*',  # í’ˆì§ˆ ì ìˆ˜: **8**
        ]
        
        for pattern in score_patterns:
            try:
                match = re.search(pattern, reflection, re.IGNORECASE | re.MULTILINE)
                if match:
                    score = float(match.group(1))
                    if 1 <= score <= 10:
                        llm_stated_score = score
                        logger.info(f"ğŸ“Š [Reflector] LLM ëª…ì‹œ ì ìˆ˜: {score}")
                        break
            except Exception as e:
                continue
        
        # âœ¨ 3ë‹¨ê³„: ìµœì¢… ì ìˆ˜ ê²°ì • (í•­ëª©ë³„ í•©ì‚° ìš°ì„ )
        # ê·œì¹™: í•­ëª©ë³„ í•©ì‚° ì ìˆ˜ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©, ì—†ìœ¼ë©´ LLM ëª…ì‹œ ì ìˆ˜ ì‚¬ìš©
        quality_score = None
        
        if calculated_score is not None:
            quality_score = calculated_score
            if llm_stated_score is not None and abs(calculated_score - llm_stated_score) > 0.5:
                logger.warning(f"âš ï¸ [Reflector] ì ìˆ˜ ë¶ˆì¼ì¹˜! í•©ì‚°: {calculated_score}, LLM ëª…ì‹œ: {llm_stated_score} â†’ í•©ì‚° ì ìˆ˜ ì‚¬ìš©")
        elif llm_stated_score is not None:
            quality_score = llm_stated_score
            logger.info(f"ğŸ“Š [Reflector] LLM ëª…ì‹œ ì ìˆ˜ ì‚¬ìš©: {llm_stated_score}")
        
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
        if quality_score is None:
            logger.warning(f"âš ï¸ [Reflector] ì ìˆ˜ íŒŒì‹± ì‹¤íŒ¨!")
            if previous_score is not None:
                quality_score = previous_score
                logger.warning(f"âš ï¸ [Reflector] ì´ì „ ì ìˆ˜ ìœ ì§€: {quality_score}")
            else:
                quality_score = 5.0
                logger.warning(f"âš ï¸ [Reflector] ê¸°ë³¸ê°’ ì‚¬ìš©: {quality_score}")
        
        # ê°œì„ í­ ê³„ì‚°
        improvement = 0.0
        if previous_score is not None:
            improvement = quality_score - previous_score
        
        logger.info(f"âœ… [Reflector] ì™„ë£Œ - ì ìˆ˜: {quality_score}/10" + 
                   (f" (ê°œì„ í­: {improvement:+.1f})" if previous_score else ""))
        
        # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        revision_history = state.get('revision_history', [])
        revision_history.append({
            'iteration': iteration,
            'draft': state['current_draft'],
            'reflection': reflection,
            'quality_score': quality_score,
            'previous_score': previous_score,
            'improvement': improvement
        })
        
        # ë©”ì‹œì§€ì— ê°œì„ í­ ì •ë³´ ì¶”ê°€
        improvement_info = ""
        if previous_score is not None:
            if improvement > 0:
                improvement_info = f"\n\nğŸ“ˆ **ê°œì„ í­:** +{improvement:.1f}ì  (ì´ì „: {previous_score} â†’ í˜„ì¬: {quality_score})"
            elif improvement < 0:
                improvement_info = f"\n\nğŸ“‰ **í‡´í™” ê°ì§€:** {improvement:.1f}ì  (ì´ì „: {previous_score} â†’ í˜„ì¬: {quality_score})"
            else:
                improvement_info = f"\n\nâ¡ï¸ **ì ìˆ˜ ìœ ì§€:** {quality_score}ì  (ë³€í™” ì—†ìŒ)"
        
        return {
            'reflection': reflection,
            'quality_score': quality_score,
            'revision_history': revision_history,
            'messages': [AIMessage(content=f"**[Reflector - í’ˆì§ˆ í‰ê°€ (Iteration {iteration})]**\n\n{reflection}{improvement_info}")]
        }
    
    def should_continue(self, state: ReflectionState) -> str:
        """ë°˜ë³µ ê³„ì† ì—¬ë¶€ ê²°ì • (3ê°€ì§€ ì¢…ë£Œ ì¡°ê±´)"""
        iteration = state.get('iteration', 0)
        quality_score = state.get('quality_score', 0)
        previous_score = state.get('previous_score')
        max_iterations = state.get('max_iterations', self.max_iterations)
        quality_threshold = state.get('quality_threshold', self.quality_threshold)
        improvement_threshold = state.get('improvement_threshold', self.improvement_threshold)
        
        # ì¢…ë£Œ ì¡°ê±´ 1: í’ˆì§ˆ ê¸°ì¤€ ì¶©ì¡±
        if quality_score >= quality_threshold:
            logger.info(f"âœ… [ì¢…ë£Œ ì¡°ê±´ 1] í’ˆì§ˆ ê¸°ì¤€ ì¶©ì¡± ({quality_score} >= {quality_threshold})")
            return "finalize"
        
        # ì¢…ë£Œ ì¡°ê±´ 2: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬
        if iteration >= max_iterations:
            logger.info(f"âš ï¸ [ì¢…ë£Œ ì¡°ê±´ 2] ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ({iteration}/{max_iterations})")
            return "finalize"
        
        # ì¢…ë£Œ ì¡°ê±´ 3: ê°œì„  ì •ì²´ ë˜ëŠ” í‡´í™” ê°ì§€ (2íšŒì°¨ ì´í›„)
        if previous_score is not None:
            improvement = quality_score - previous_score
            
            # í‡´í™” ê°ì§€: ì ìˆ˜ê°€ í•˜ë½í•œ ê²½ìš°
            if improvement < 0:
                logger.info(f"âš ï¸ [ì¢…ë£Œ ì¡°ê±´ 3] í‡´í™” ê°ì§€ ({previous_score} â†’ {quality_score}, ê°œì„ í­: {improvement:.1f})")
                return "finalize"
            
            # ê°œì„  ì •ì²´: ê°œì„ í­ì´ ì„ê³„ê°’ ë¯¸ë§Œ
            if improvement < improvement_threshold and iteration >= 2:
                logger.info(f"âš ï¸ [ì¢…ë£Œ ì¡°ê±´ 3] ê°œì„  ì •ì²´ (ê°œì„ í­ {improvement:.2f} < {improvement_threshold})")
                return "finalize"
        
        logger.info(f"ğŸ”„ ê°œì„  ê³„ì† ({quality_score} < {quality_threshold}, iteration {iteration}/{max_iterations})")
        return "revise"
    
    async def finalizer_node(self, state: ReflectionState) -> dict:
        """Finalizer: ìµœì¢… ì¶œë ¥ ìƒì„± (Reflector ì ìˆ˜ ì¼ê´€ì„± ë³´ì¥)"""
        logger.info("ğŸ¯ [Finalizer] ìµœì¢… ê²°ê³¼ ìƒì„± ì¤‘...")
        
        iteration = state.get('iteration', 0)
        revision_history = state.get('revision_history', [])
        
        # âœ… ì ìˆ˜ íˆìŠ¤í† ë¦¬ ì¶”ì¶œ (revision_historyì—ì„œ ê°€ì ¸ì˜´)
        score_history = []
        for h in revision_history:
            if 'quality_score' in h and h['quality_score'] is not None:
                score_history.append(h['quality_score'])
        
        # âœ… í•µì‹¬ ê·œì¹™: Final Score = Last Reflector Score
        # 1ìˆœìœ„: revision_historyì˜ ë§ˆì§€ë§‰ ì ìˆ˜
        # 2ìˆœìœ„: stateì˜ quality_score
        # 3ìˆœìœ„: ê¸°ë³¸ê°’ (ì´ ê²½ìš°ëŠ” ì˜¤ë¥˜ ìƒí™©)
        if score_history:
            final_score = score_history[-1]  # ë§ˆì§€ë§‰ Reflector ì ìˆ˜ ì‚¬ìš©
            logger.info(f"ğŸ“Š [Finalizer] ì ìˆ˜ íˆìŠ¤í† ë¦¬ì—ì„œ ìµœì¢… ì ìˆ˜ ì¶”ì¶œ: {final_score}")
        elif state.get('quality_score') is not None:
            final_score = state.get('quality_score')
            logger.info(f"ğŸ“Š [Finalizer] stateì—ì„œ ìµœì¢… ì ìˆ˜ ì¶”ì¶œ: {final_score}")
        else:
            final_score = 7.0  # íŒŒì‹± ì™„ì „ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
            logger.warning(f"âš ï¸ [Finalizer] ì ìˆ˜ ì¶”ì¶œ ì‹¤íŒ¨ - ê¸°ë³¸ê°’ ì‚¬ìš©: {final_score}")
        
        # í‰ê·  ì ìˆ˜ ê³„ì‚°
        avg_score = sum(score_history) / len(score_history) if score_history else final_score
        
        # ì¢…ë£Œ ì‚¬ìœ  ë¶„ì„
        termination_reason = "ì•Œ ìˆ˜ ì—†ìŒ"
        quality_threshold = state.get('quality_threshold', self.quality_threshold)
        max_iterations = state.get('max_iterations', self.max_iterations)
        
        if final_score >= quality_threshold:
            termination_reason = f"âœ… í’ˆì§ˆ ê¸°ì¤€ ì¶©ì¡± ({final_score:.1f} >= {quality_threshold})"
        elif iteration >= max_iterations:
            termination_reason = f"â±ï¸ ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ({iteration}/{max_iterations})"
        elif len(score_history) >= 2:
            last_improvement = score_history[-1] - score_history[-2]
            if last_improvement < 0:
                termination_reason = f"ğŸ“‰ í‡´í™” ê°ì§€ (ê°œì„ í­: {last_improvement:+.1f})"
            elif last_improvement < self.improvement_threshold:
                termination_reason = f"ğŸ“Š ê°œì„  ì •ì²´ (ê°œì„ í­: {last_improvement:.2f} < {self.improvement_threshold})"
        
        # ì ìˆ˜ ë³€í™” ì¶”ì´ ë¬¸ìì—´
        score_trend = " â†’ ".join([f"{s:.1f}" for s in score_history]) if score_history else f"{final_score:.1f}"
        
        # ë¡œê¹…: ì ìˆ˜ ì¼ê´€ì„± ê²€ì¦
        logger.info(f"ğŸ“Š [Finalizer] ì ìˆ˜ ê²€ì¦ - íˆìŠ¤í† ë¦¬: {score_history}, ìµœì¢…: {final_score}")
        
        summary = f"""**Reflection ì™„ë£Œ**

**ì¢…ë£Œ ì‚¬ìœ :** {termination_reason}

**ë°˜ë³µ í†µê³„:**
- ì´ ë°˜ë³µ íšŸìˆ˜: {iteration}íšŒ
- ì ìˆ˜ ë³€í™”: {score_trend}
- í‰ê·  ì ìˆ˜: {avg_score:.1f}/10
- **ìµœì¢… ì ìˆ˜: {final_score:.1f}/10** (ë§ˆì§€ë§‰ Reflector í‰ê°€ ê¸°ì¤€)

---

**ìµœì¢… ê²°ê³¼:**
{state['current_draft']}"""
        
        logger.info(f"âœ… [Finalizer] ì™„ë£Œ - {iteration}íšŒ ë°˜ë³µ, ìµœì¢… ì ìˆ˜: {final_score:.1f}/10")
        
        return {
            'final_output': state['current_draft'],
            'termination_reason': termination_reason,
            'messages': [AIMessage(content=summary)]
        }
    
    def create_graph(self) -> StateGraph:
        """Reflection ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„±"""
        workflow = StateGraph(ReflectionState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("generator", self.generator_node)
        workflow.add_node("reflector", self.reflector_node)
        workflow.add_node("finalizer", self.finalizer_node)
        
        # ì—£ì§€ ì¶”ê°€
        workflow.set_entry_point("generator")
        workflow.add_edge("generator", "reflector")
        
        # ì¡°ê±´ë¶€ ì—£ì§€: ê³„ì† ê°œì„ í• ì§€ ì¢…ë£Œí• ì§€
        workflow.add_conditional_edges(
            "reflector",
            self.should_continue,
            {
                "revise": "generator",  # ê°œì„  í•„ìš” â†’ Generatorë¡œ ëŒì•„ê°
                "finalize": "finalizer"  # í’ˆì§ˆ ì¶©ì¡±/ì •ì²´/í‡´í™” â†’ ì¢…ë£Œ
            }
        )
        
        workflow.add_edge("finalizer", END)
        
        logger.info("âœ… [Reflection] ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ - ìƒì„±â†’í‰ê°€â†’ê°œì„  ë£¨í”„ (ê°œì„ í­/í‡´í™” ê°ì§€ í¬í•¨)")
        return workflow.compile()


# ============================================================================
# 8ï¸âƒ£ Routing / Dynamic Orchestration Pattern (ë‹¤ì¤‘ í›„ë³´ ê²½ìŸ)
# ============================================================================

class RoutingPattern:
    """
    Dynamic Routing / Orchestration Pattern: ë‹¤ì¤‘ í›„ë³´ ê²½ìŸ ê¸°ë°˜ ë™ì  ë¼ìš°íŒ…
    
    âœ¨ í•µì‹¬ 3ìš”ì†Œ (ì—…ê·¸ë ˆì´ë“œ):
    1. Router: ëª¨ë“  í›„ë³´ ì „ë¬¸ê°€ì— ëŒ€í•œ ì í•©ë„ ì ìˆ˜ ì‚°ì¶œ â†’ ìµœê³  ì ìˆ˜ ì„ íƒ
    2. Specialist Agents: ê° ë¶„ì•¼ ì „ë¬¸ ì—ì´ì „íŠ¸ (ë³‘ë ¬ í‰ê°€ ëŒ€ìƒ)
    3. Aggregator: ì ìˆ˜í‘œ + íƒˆë½ ì‚¬ìœ  + ìµœì¢… ê²°ê³¼ í†µí•©
    
    âœ¨ ë¼ìš°íŒ… íë¦„:
    [User Request]
         â†“
    [Router] â”€â”¬â”€ ê¸°ìˆ  ì „ë¬¸ê°€: 0.92 â† ì„ íƒ!
              â”œâ”€ ë³´ì•ˆ ì „ë¬¸ê°€: 0.65
              â”œâ”€ ë¹„ì¦ˆë‹ˆìŠ¤ ì „ë¬¸ê°€: 0.40
              â””â”€ ì¼ë°˜ ì–´ì‹œìŠ¤í„´íŠ¸: 0.25
         â†“
    [Selected Expert Agent]
         â†“
    [Aggregator] â†’ ì ìˆ˜í‘œ + íƒˆë½ ì‚¬ìœ  + ì‘ë‹µ
    
    âœ¨ vs ê¸°ë³¸í˜•:
    - ê¸°ë³¸í˜•: if "ì‹œìŠ¤í…œ" in query â†’ ê¸°ìˆ ì „ë¬¸ê°€ (ì •ì )
    - ì—…ê·¸ë ˆì´ë“œ: ëª¨ë“  í›„ë³´ ì ìˆ˜ ê³„ì‚° â†’ ìµœê³  ì ìˆ˜ ì„ íƒ (ë™ì  ê²½ìŸ)
    """
    
    # ì „ë¬¸ ì—ì´ì „íŠ¸ ì •ì˜ (ë³´ì•ˆ ì „ë¬¸ê°€ ì¶”ê°€)
    SPECIALIST_AGENTS = {
        "technical": {
            "name": "ê¸°ìˆ  ì „ë¬¸ê°€",
            "emoji": "ğŸ’»",
            "description": "ê¸°ìˆ ì ì¸ ì§ˆë¬¸, ì½”ë“œ, ì•„í‚¤í…ì²˜, ì‹œìŠ¤í…œ ì„¤ê³„, ì¸í”„ë¼ ê´€ë ¨",
            "strengths": ["ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜", "ì½”ë“œ ë¦¬ë·°", "ê¸°ìˆ  ìŠ¤íƒ ì„ íƒ", "ì„±ëŠ¥ ìµœì í™”"],
            "keywords": ["ì½”ë“œ", "ê°œë°œ", "ê¸°ìˆ ", "ì‹œìŠ¤í…œ", "ì•„í‚¤í…ì²˜", "API", "ì„œë²„", "ë°ì´í„°ë² ì´ìŠ¤", "ì¸í”„ë¼"]
        },
        "security": {
            "name": "ë³´ì•ˆ ì „ë¬¸ê°€",
            "emoji": "ğŸ”’",
            "description": "ë³´ì•ˆ ì •ì±…, ì·¨ì•½ì  ë¶„ì„, ì»´í”Œë¼ì´ì–¸ìŠ¤, ì¸ì¦/ì¸ê°€ ê´€ë ¨",
            "strengths": ["ì·¨ì•½ì  ë¶„ì„", "ë³´ì•ˆ ì•„í‚¤í…ì²˜", "ì»´í”Œë¼ì´ì–¸ìŠ¤", "ì¹¨í•´ ëŒ€ì‘"],
            "keywords": ["ë³´ì•ˆ", "ì·¨ì•½ì ", "ì¸ì¦", "ì•”í˜¸í™”", "í•´í‚¹", "ë°©í™”ë²½", "ì ‘ê·¼ì œì–´", "ê°ì‚¬"]
        },
        "business": {
            "name": "ë¹„ì¦ˆë‹ˆìŠ¤ ì „ë¬¸ê°€",
            "emoji": "ğŸ“Š",
            "description": "ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµ, ì‹œì¥ ë¶„ì„, ROI, ìˆ˜ìµ ëª¨ë¸ ê´€ë ¨",
            "strengths": ["ì‹œì¥ ë¶„ì„", "ROI ê³„ì‚°", "ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸", "ê²½ìŸ ë¶„ì„"],
            "keywords": ["ë¹„ì¦ˆë‹ˆìŠ¤", "ìˆ˜ìµ", "ì‹œì¥", "ì „ëµ", "ROI", "ê³ ê°", "ë§¤ì¶œ", "ë§ˆì¼€íŒ…", "íˆ¬ì"]
        },
        "creative": {
            "name": "í¬ë¦¬ì—ì´í‹°ë¸Œ ì „ë¬¸ê°€",
            "emoji": "ğŸ¨",
            "description": "ì°½ì‘, ì½˜í…ì¸ , ë””ìì¸, UX/UI, ë¸Œëœë”© ê´€ë ¨",
            "strengths": ["UX ì„¤ê³„", "ë””ìì¸ ì‹œìŠ¤í…œ", "ì½˜í…ì¸  ì „ëµ", "ë¸Œëœë”©"],
            "keywords": ["ë””ìì¸", "ì½˜í…ì¸ ", "ì°½ì‘", "ë¸Œëœë”©", "UX", "UI", "ìŠ¤í† ë¦¬", "ê²½í—˜"]
        },
        "general": {
            "name": "ì¼ë°˜ ì–´ì‹œìŠ¤í„´íŠ¸",
            "emoji": "ğŸ¤–",
            "description": "ì¼ë°˜ì ì¸ ì§ˆë¬¸, ë¶„ë¥˜ê°€ ë¶ˆë¶„ëª…í•œ ìš”ì²­, ê¸°íƒ€",
            "strengths": ["ì¼ë°˜ ì§€ì‹", "ìš”ì•½", "ì •ë¦¬", "ê¸°íƒ€"],
            "keywords": []
        }
    }
    
    # ì„ íƒ ì„ê³„ê°’ (ì´ ì´ìƒì´ë©´ í•´ë‹¹ ì „ë¬¸ê°€ ì„ íƒ ê°€ëŠ¥)
    SELECTION_THRESHOLD = 0.3
    
    def __init__(self, llm_service, stream_callback: Optional[StreamCallback] = None):
        self.llm_service = llm_service
        self.stream_callback = stream_callback
    
    def set_stream_callback(self, callback: Optional[StreamCallback]):
        """ìŠ¤íŠ¸ë¦¬ë° ì½œë°± ì„¤ì •"""
        self.stream_callback = callback
    
    async def _generate_with_streaming(self, prompt: str, node_name: str) -> str:
        """ìŠ¤íŠ¸ë¦¬ë° ì½œë°±ì´ ìˆìœ¼ë©´ í† í° ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë°, ì—†ìœ¼ë©´ ì¼ë°˜ ìƒì„±"""
        if self.stream_callback:
            content = ""
            async for token in self.llm_service.generate_response_stream(prompt):
                content += token
                await self.stream_callback(node_name, token)
            return content
        else:
            return await self.llm_service.generate_response(prompt)
    
    async def router_node(self, state: RoutingState) -> dict:
        """
        Router: ë‹¤ì¤‘ í›„ë³´ ê²½ìŸ ê¸°ë°˜ ë™ì  ë¼ìš°íŒ…
        
        ëª¨ë“  ì „ë¬¸ê°€ì— ëŒ€í•´ ì í•©ë„ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ê³ , ìµœê³  ì ìˆ˜ ì „ë¬¸ê°€ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
        """
        logger.info("ğŸ”€ [Router] ë‹¤ì¤‘ í›„ë³´ ê²½ìŸ í‰ê°€ ì‹œì‘...")
        
        user_request = state['user_request']
        
        # ëª¨ë“  ì „ë¬¸ê°€ ì •ë³´ êµ¬ì„±
        agents_detailed = []
        for key, info in self.SPECIALIST_AGENTS.items():
            agents_detailed.append(f"""- **{key}** ({info['emoji']} {info['name']}):
  - ì „ë¬¸ ë¶„ì•¼: {info['description']}
  - ê°•ì : {', '.join(info['strengths'])}""")
        
        agents_desc = "\n".join(agents_detailed)
        
        # âœ¨ ë‹¤ì¤‘ í›„ë³´ ê²½ìŸ í‰ê°€ í”„ë¡¬í”„íŠ¸
        prompt = f"""ë‹¹ì‹ ì€ ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ ì „ë¬¸ê°€ë¥¼ ì„ íƒí•˜ëŠ” ë¼ìš°í„°ì…ë‹ˆë‹¤.

**ì‚¬ìš©ì ìš”ì²­:**
{user_request}

**ê°€ìš© ì „ë¬¸ê°€ ëª©ë¡:**
{agents_desc}

---

## ğŸ¯ í‰ê°€ ì§€ì¹¨

ê° ì „ë¬¸ê°€ì— ëŒ€í•´ **ì í•©ë„ ì ìˆ˜(0.0~1.0)**ë¥¼ í‰ê°€í•˜ì„¸ìš”.

**ì ìˆ˜ ê¸°ì¤€:**
- 0.9~1.0: ì™„ë²½í•œ ë§¤ì¹­ (í•´ë‹¹ ì „ë¬¸ê°€ì˜ í•µì‹¬ ì˜ì—­)
- 0.7~0.8: ë†’ì€ ì í•©ë„ (ê´€ë ¨ì„± ë†’ìŒ)
- 0.5~0.6: ì¤‘ê°„ ì í•©ë„ (ë¶€ë¶„ì  ê´€ë ¨)
- 0.3~0.4: ë‚®ì€ ì í•©ë„ (ì•½ê°„ì˜ ê´€ë ¨)
- 0.0~0.2: ê±°ì˜ ë¬´ê´€í•¨

---

ë‹¤ìŒ **JSON í˜•ì‹ìœ¼ë¡œë§Œ** ì‘ë‹µí•˜ì„¸ìš”:

```json
{{
    "analysis": "ìš”ì²­ ë¶„ì„ ë‚´ìš© (1-2ë¬¸ì¥)",
    "scores": {{
        "technical": {{"score": 0.0, "reason": "ì ìˆ˜ ì‚¬ìœ "}},
        "security": {{"score": 0.0, "reason": "ì ìˆ˜ ì‚¬ìœ "}},
        "business": {{"score": 0.0, "reason": "ì ìˆ˜ ì‚¬ìœ "}},
        "creative": {{"score": 0.0, "reason": "ì ìˆ˜ ì‚¬ìœ "}},
        "general": {{"score": 0.0, "reason": "ì ìˆ˜ ì‚¬ìœ "}}
    }},
    "selected": "ìµœê³  ì ìˆ˜ ì „ë¬¸ê°€ í‚¤",
    "selection_reason": "ì„ íƒ ê·¼ê±° (êµ¬ì²´ì ìœ¼ë¡œ)"
}}
```

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."""
        
        response = await self._generate_with_streaming(prompt, "router")
        
        # JSON íŒŒì‹±
        import re
        candidate_scores = {}
        elimination_reasons = {}
        selected_agent = "general"
        confidence = 0.5
        analysis = ""
        selection_reason = ""
        
        try:
            # JSON ì¶”ì¶œ
            json_str = response
            if '```json' in response:
                json_str = response.split('```json')[1].split('```')[0].strip()
            elif '```' in response:
                json_str = response.split('```')[1].split('```')[0].strip()
            
            data = json.loads(json_str)
            
            analysis = data.get("analysis", "")
            scores_data = data.get("scores", {})
            selected_agent = data.get("selected", "general")
            selection_reason = data.get("selection_reason", "")
            
            # ì ìˆ˜ ì •ë³´ ì¶”ì¶œ
            max_score = 0.0
            for agent_key, score_info in scores_data.items():
                if agent_key in self.SPECIALIST_AGENTS:
                    score = float(score_info.get("score", 0.0))
                    reason = score_info.get("reason", "")
                    
                    candidate_scores[agent_key] = {
                        "score": score,
                        "reason": reason,
                        "name": self.SPECIALIST_AGENTS[agent_key]["name"],
                        "emoji": self.SPECIALIST_AGENTS[agent_key]["emoji"]
                    }
                    
                    if score > max_score:
                        max_score = score
                        selected_agent = agent_key
                    
                    # íƒˆë½ ì‚¬ìœ  ìƒì„± (ì„ íƒë˜ì§€ ì•Šì€ ê²½ìš°)
                    if score < max_score:
                        elimination_reasons[agent_key] = reason
            
            confidence = max_score
            
            # ìµœì¢… ì„ íƒëœ ì—ì´ì „íŠ¸ í™•ì¸
            if selected_agent not in self.SPECIALIST_AGENTS:
                selected_agent = "general"
            
            # íƒˆë½ ì‚¬ìœ  ì¬êµ¬ì„± (ì„ íƒëœ ì—ì´ì „íŠ¸ ì œì™¸)
            elimination_reasons = {}
            sorted_candidates = sorted(candidate_scores.items(), key=lambda x: x[1]["score"], reverse=True)
            for agent_key, info in sorted_candidates[1:]:  # 1ë“± ì œì™¸
                elimination_reasons[agent_key] = info["reason"]
            
            logger.info(f"âœ… [Router] ì ìˆ˜ íŒŒì‹± ì™„ë£Œ - {len(candidate_scores)}ê°œ í›„ë³´ í‰ê°€")
            
        except Exception as e:
            logger.error(f"âŒ [Router] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê¸°ë³¸ ì ìˆ˜
            for agent_key in self.SPECIALIST_AGENTS.keys():
                candidate_scores[agent_key] = {
                    "score": 0.2 if agent_key != "general" else 0.5,
                    "reason": "íŒŒì‹± ì‹¤íŒ¨ë¡œ ê¸°ë³¸ê°’ ì ìš©",
                    "name": self.SPECIALIST_AGENTS[agent_key]["name"],
                    "emoji": self.SPECIALIST_AGENTS[agent_key]["emoji"]
                }
            selected_agent = "general"
            confidence = 0.5
        
        agent_info = self.SPECIALIST_AGENTS[selected_agent]
        
        routing_decision = {
            "selected_agent": selected_agent,
            "agent_name": agent_info["name"],
            "agent_emoji": agent_info["emoji"],
            "confidence": confidence,
            "analysis": analysis,
            "selection_reason": selection_reason
        }
        
        # ë¼ìš°íŒ… ë¡œê·¸ ì—…ë°ì´íŠ¸
        routing_log = state.get('routing_log', [])
        routing_log.append({
            "request": user_request,
            "decision": routing_decision,
            "all_scores": candidate_scores
        })
        
        logger.info(f"âœ… [Router] {agent_info['emoji']} {agent_info['name']} ì„ íƒ (ì í•©ë„: {confidence:.0%})")
        
        # âœ¨ ì ìˆ˜í‘œ ë©”ì‹œì§€ ìƒì„±
        sorted_scores = sorted(candidate_scores.items(), key=lambda x: x[1]["score"], reverse=True)
        
        score_table_rows = []
        for i, (agent_key, info) in enumerate(sorted_scores):
            rank = f"ğŸ¥‡" if i == 0 else f"ğŸ¥ˆ" if i == 1 else f"ğŸ¥‰" if i == 2 else f" {i+1}"
            selected_mark = "âœ… **ì„ íƒ**" if agent_key == selected_agent else ""
            bar_length = int(info["score"] * 20)
            score_bar = "â–ˆ" * bar_length + "â–‘" * (20 - bar_length)
            score_table_rows.append(
                f"| {rank} | {info['emoji']} {info['name']} | {score_bar} | **{info['score']:.0%}** | {selected_mark} |"
            )
        
        score_table = "\n".join(score_table_rows)
        
        message_content = f"""**[Router - ë‹¤ì¤‘ í›„ë³´ ê²½ìŸ í‰ê°€]**

**ğŸ“ ìš”ì²­ ë¶„ì„:**
{analysis if analysis else user_request}

---

**ğŸ“Š ì „ë¬¸ê°€ë³„ ì í•©ë„ ì ìˆ˜í‘œ:**

| ìˆœìœ„ | ì „ë¬¸ê°€ | ì í•©ë„ | ì ìˆ˜ | ì„ íƒ |
|------|--------|--------|------|------|
{score_table}

---

**ğŸ¯ ë¼ìš°íŒ… ê²°ì •:**
- **ì„ íƒëœ ì „ë¬¸ê°€:** {agent_info['emoji']} **{agent_info['name']}**
- **ì í•©ë„ ì ìˆ˜:** {confidence:.0%}
- **ì„ íƒ ê·¼ê±°:** {selection_reason if selection_reason else "ìµœê³  ì ìˆ˜ ì „ë¬¸ê°€"}

**ğŸ“‹ í‰ê°€ ì„¸ë¶€ ë‚´ìš©:**
{chr(10).join([f"- {info['emoji']} {info['name']}: {info['reason']}" for _, info in sorted_scores])}"""
        
        return {
            'routing_decision': routing_decision,
            'selected_agent': selected_agent,
            'confidence_score': confidence,
            'candidate_scores': candidate_scores,
            'elimination_reasons': elimination_reasons,
            'routing_log': routing_log,
            'messages': [AIMessage(content=message_content)]
        }
    
    async def technical_agent(self, state: RoutingState) -> dict:
        """ê¸°ìˆ  ì „ë¬¸ê°€ ì—ì´ì „íŠ¸"""
        return await self._specialist_logic("technical", state)
    
    async def security_agent(self, state: RoutingState) -> dict:
        """ë³´ì•ˆ ì „ë¬¸ê°€ ì—ì´ì „íŠ¸"""
        return await self._specialist_logic("security", state)
    
    async def business_agent(self, state: RoutingState) -> dict:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ì „ë¬¸ê°€ ì—ì´ì „íŠ¸"""
        return await self._specialist_logic("business", state)
    
    async def creative_agent(self, state: RoutingState) -> dict:
        """í¬ë¦¬ì—ì´í‹°ë¸Œ ì „ë¬¸ê°€ ì—ì´ì „íŠ¸"""
        return await self._specialist_logic("creative", state)
    
    async def general_agent(self, state: RoutingState) -> dict:
        """ì¼ë°˜ ì–´ì‹œìŠ¤í„´íŠ¸ ì—ì´ì „íŠ¸"""
        return await self._specialist_logic("general", state)
    
    async def _specialist_logic(self, agent_type: str, state: RoutingState) -> dict:
        """ì „ë¬¸ ì—ì´ì „íŠ¸ ê³µí†µ ë¡œì§"""
        agent_info = self.SPECIALIST_AGENTS[agent_type]
        logger.info(f"ğŸ¯ [{agent_info['emoji']} {agent_info['name']}] ì‘ë‹µ ìƒì„± ì¤‘...")
        
        prompt = f"""ë‹¹ì‹ ì€ {agent_info['emoji']} **{agent_info['name']}**ì…ë‹ˆë‹¤.

**ì „ë¬¸ ë¶„ì•¼:** {agent_info['description']}
**í•µì‹¬ ê°•ì :** {', '.join(agent_info['strengths'])}

ë‹¤ìŒ ìš”ì²­ì— ëŒ€í•´ ë‹¹ì‹ ì˜ ì „ë¬¸ ë¶„ì•¼ ê´€ì ì—ì„œ ìƒì„¸í•˜ê³  ì‹¤ìš©ì ì¸ ì‘ë‹µì„ ì œê³µí•˜ì„¸ìš”.

**ì‚¬ìš©ì ìš”ì²­:**
{state['user_request']}

---

ì „ë¬¸ê°€ë‹µê²Œ ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•˜ì—¬ ì‘ë‹µí•˜ì„¸ìš”:
1. í•µì‹¬ ë¶„ì„/ë‹µë³€
2. êµ¬ì²´ì ì¸ ê¶Œì¥ ì‚¬í•­
3. ì£¼ì˜ ì‚¬í•­ ë˜ëŠ” ê³ ë ¤ ì‚¬í•­

ì „ë¬¸ ìš©ì–´ëŠ” ì„¤ëª…ì„ ë§ë¶™ì´ê³ , ì‹¤ë¬´ì—ì„œ ë°”ë¡œ í™œìš© ê°€ëŠ¥í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”."""
        
        response = await self._generate_with_streaming(prompt, agent_type)
        
        logger.info(f"âœ… [{agent_info['name']}] ì‘ë‹µ ì™„ë£Œ")
        
        return {
            'agent_result': response,
            'messages': [AIMessage(content=f"**[{agent_info['emoji']} {agent_info['name']} ì‘ë‹µ]**\n\n{response}")]
        }
    
    def route_to_agent(self, state: RoutingState) -> str:
        """ì„ íƒëœ ì—ì´ì „íŠ¸ë¡œ ë¼ìš°íŒ…"""
        selected = state.get('selected_agent', 'general')
        return selected
    
    async def aggregator_node(self, state: RoutingState) -> dict:
        """
        Aggregator: ê²°ê³¼ í†µí•© + ì ìˆ˜í‘œ + íƒˆë½ ì‚¬ìœ 
        
        âœ¨ ì‹¤ë¬´ê¸‰ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì¶œë ¥:
        - ì „ì²´ ì ìˆ˜í‘œ
        - ì„ íƒëœ ì „ë¬¸ê°€ ì •ë³´
        - íƒˆë½ ì „ë¬¸ê°€ ì‚¬ìœ 
        - ìµœì¢… ì‘ë‹µ
        """
        logger.info("ğŸ“Š [Aggregator] ê²°ê³¼ í†µí•© ì¤‘...")
        
        routing_decision = state.get('routing_decision', {})
        candidate_scores = state.get('candidate_scores', {})
        elimination_reasons = state.get('elimination_reasons', {})
        agent_result = state.get('agent_result', '')
        
        # ì ìˆ˜í‘œ ìƒì„±
        sorted_scores = sorted(candidate_scores.items(), key=lambda x: x[1]["score"], reverse=True)
        
        score_summary = []
        for i, (agent_key, info) in enumerate(sorted_scores):
            rank_emoji = "ğŸ¥‡" if i == 0 else "ğŸ¥ˆ" if i == 1 else "ğŸ¥‰" if i == 2 else f"#{i+1}"
            status = "âœ… ì„ íƒë¨" if agent_key == routing_decision.get('selected_agent') else "âŒ íƒˆë½"
            score_summary.append(f"- {rank_emoji} {info['emoji']} {info['name']}: **{info['score']:.0%}** ({status})")
        
        score_summary_text = "\n".join(score_summary)
        
        # íƒˆë½ ì‚¬ìœ  ìƒì„±
        elimination_text = ""
        if elimination_reasons:
            elimination_items = []
            for agent_key, reason in elimination_reasons.items():
                if agent_key in candidate_scores:
                    info = candidate_scores[agent_key]
                    elimination_items.append(f"- {info['emoji']} {info['name']}: {reason}")
            if elimination_items:
                elimination_text = f"""
---

**âŒ íƒˆë½ ì‚¬ìœ :**
{chr(10).join(elimination_items)}"""
        
        summary = f"""**[ìµœì¢… ì‘ë‹µ - Dynamic Orchestration]**

---

**ğŸ“Š ë¼ìš°íŒ… ì ìˆ˜í‘œ:**
{score_summary_text}

---

**ğŸ¯ ì„ íƒëœ ì „ë¬¸ê°€:**
- {routing_decision.get('agent_emoji', 'ğŸ¤–')} **{routing_decision.get('agent_name', 'N/A')}**
- ì í•©ë„: **{routing_decision.get('confidence', 0):.0%}**
- ì„ íƒ ê·¼ê±°: {routing_decision.get('selection_reason', 'N/A')}
{elimination_text}

---

**ğŸ“ ì „ë¬¸ê°€ ì‘ë‹µ:**

{agent_result}"""
        
        logger.info("âœ… [Aggregator] ì™„ë£Œ - ì ìˆ˜í‘œ ë° íƒˆë½ ì‚¬ìœ  í¬í•¨")
        
        return {
            'final_response': agent_result,
            'messages': [AIMessage(content=summary)]
        }
    
    def create_graph(self) -> StateGraph:
        """Dynamic Routing ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„±"""
        workflow = StateGraph(RoutingState)
        
        # ë…¸ë“œ ì¶”ê°€ (ë³´ì•ˆ ì „ë¬¸ê°€ ì¶”ê°€)
        workflow.add_node("router", self.router_node)
        workflow.add_node("technical", self.technical_agent)
        workflow.add_node("security", self.security_agent)  # âœ¨ ì¶”ê°€
        workflow.add_node("business", self.business_agent)
        workflow.add_node("creative", self.creative_agent)
        workflow.add_node("general", self.general_agent)
        workflow.add_node("aggregator", self.aggregator_node)
        
        # ì—£ì§€ ì¶”ê°€
        workflow.set_entry_point("router")
        
        # ì¡°ê±´ë¶€ ì—£ì§€: Router ê²°ê³¼ì— ë”°ë¼ ë¶„ê¸°
        workflow.add_conditional_edges(
            "router",
            self.route_to_agent,
            {
                "technical": "technical",
                "security": "security",  # âœ¨ ì¶”ê°€
                "business": "business",
                "creative": "creative",
                "general": "general"
            }
        )
        
        # ëª¨ë“  ì „ë¬¸ ì—ì´ì „íŠ¸ â†’ Aggregator
        workflow.add_edge("technical", "aggregator")
        workflow.add_edge("security", "aggregator")  # âœ¨ ì¶”ê°€
        workflow.add_edge("business", "aggregator")
        workflow.add_edge("creative", "aggregator")
        workflow.add_edge("general", "aggregator")
        
        workflow.add_edge("aggregator", END)
        
        logger.info("âœ… [Dynamic Routing] ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ - ë‹¤ì¤‘ í›„ë³´ ê²½ìŸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜")
        return workflow.compile()


# ============================================================================
# 9ï¸âƒ£ Human-in-the-Loop (HITL) Pattern - ì‹¤ì œ ì‚¬ëŒ ê°œì…
# ============================================================================

class HITLPattern:
    """
    Human-in-the-Loop Pattern: ì‹¤ì œ ì‚¬ëŒì˜ ê²€í† /ìŠ¹ì¸/ìˆ˜ì • ì§€ì›
    
    âœ¨ í•µì‹¬ íŠ¹ì§•:
    - ì‹¤ì œ ì‚¬ëŒì´ WebSocketì„ í†µí•´ ê²°ì •ì„ ë‚´ë¦¼
    - LLM ì‹œë®¬ë ˆì´ì…˜ì´ ì•„ë‹Œ ì§„ì •í•œ Human-in-the-Loop
    
    âœ¨ 3ë‹¨ ë¶„ê¸° ê²°ì • êµ¬ì¡°:
    - âœ… APPROVE: ì œì•ˆ ìŠ¹ì¸ â†’ Finalizerë¡œ ì¢…ë£Œ
    - ğŸŸ¡ REVISION: ìˆ˜ì • ìš”ì²­ â†’ Generator ì¬í˜¸ì¶œ (í”¼ë“œë°± ë°˜ì˜)
    - â›” REJECT: ì œì•ˆ ê±°ë¶€ â†’ Finalizerë¡œ ì¢…ë£Œ
    
    âœ¨ ì›Œí¬í”Œë¡œìš°:
    [Agent: ì œì•ˆ ìƒì„±]
           â†“
    [Human Gate: ëŒ€ê¸°] â† ì‹¤ì œ ì‚¬ëŒ ê²°ì • ëŒ€ê¸°!
           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”
    âœ…     ğŸŸ¡     â›”
    ìŠ¹ì¸   ìˆ˜ì •   ê±°ë¶€
    â†“      â†“      â†“
    ì¢…ë£Œ   ì¬ìƒì„±  ì¢…ë£Œ
    """
    
    def __init__(self, llm_service, max_revisions=3, stream_callback: Optional[StreamCallback] = None):
        self.llm_service = llm_service
        self.max_revisions = max_revisions
        self.stream_callback = stream_callback
    
    def set_stream_callback(self, callback: Optional[StreamCallback]):
        """ìŠ¤íŠ¸ë¦¬ë° ì½œë°± ì„¤ì •"""
        self.stream_callback = callback
    
    async def _generate_with_streaming(self, prompt: str, node_name: str) -> str:
        """ìŠ¤íŠ¸ë¦¬ë° ì½œë°±ì´ ìˆìœ¼ë©´ í† í° ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë°, ì—†ìœ¼ë©´ ì¼ë°˜ ìƒì„±"""
        if self.stream_callback:
            content = ""
            async for token in self.llm_service.generate_response_stream(prompt):
                content += token
                await self.stream_callback(node_name, token)
            return content
        else:
            return await self.llm_service.generate_response(prompt)
    
    async def proposal_generator(self, state: HITLState) -> dict:
        """Agent: ì œì•ˆ ìƒì„± (í”¼ë“œë°± ë°˜ì˜ í¬í•¨)"""
        revision_count = state.get('revision_count', 0)
        human_feedback = state.get('human_feedback')
        revision_history = state.get('revision_history', [])
        
        if revision_count == 0:
            logger.info("ğŸ“ [Agent] ì´ˆê¸° ì œì•ˆ ìƒì„± ì¤‘...")
            prompt = f"""ë‹¤ìŒ ì‘ì—…ì— ëŒ€í•œ ìƒì„¸ ì œì•ˆì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ì‘ì—…:** {state['task']}

---

## ì œì•ˆì„œ êµ¬ì¡° (ë°˜ë“œì‹œ í¬í•¨):

### 1. ğŸ“‹ ëª©í‘œ ë° ë²”ìœ„
- í•µì‹¬ ëª©í‘œë¥¼ ëª…í™•íˆ ì •ì˜
- ë²”ìœ„ì™€ ì œì•½ ì¡°ê±´ ëª…ì‹œ

### 2. ğŸ› ï¸ ì ‘ê·¼ ë°©ë²•
- ë‹¨ê³„ë³„ ì‹¤í–‰ ê³„íš
- í•„ìš”í•œ ë¦¬ì†ŒìŠ¤ ë° ê¸°ìˆ  ìŠ¤íƒ

### 3. ğŸ“ˆ ì˜ˆìƒ ê²°ê³¼
- ì •ëŸ‰ì  ì„±ê³¼ ì§€í‘œ (KPI)
- ê¸°ëŒ€ íš¨ê³¼

### 4. âš ï¸ ë¦¬ìŠ¤í¬ ë° ëŒ€ì‘ ë°©ì•ˆ
- ì ì¬ì  ìœ„í—˜ ìš”ì†Œ
- ê° ë¦¬ìŠ¤í¬ë³„ ì™„í™” ì „ëµ

### 5. ğŸ“… ì¼ì • ë° ë§ˆì¼ìŠ¤í†¤
- ì£¼ìš” ë§ˆì¼ìŠ¤í†¤
- ì˜ˆìƒ ì†Œìš” ê¸°ê°„

---

êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì œì•ˆì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”."""
        else:
            logger.info(f"ğŸ“ [Agent] í”¼ë“œë°± ë°˜ì˜ ìˆ˜ì • ì¤‘ (ìˆ˜ì • {revision_count}íšŒ)...")
            
            # ì´ì „ ìˆ˜ì • ì´ë ¥ ìš”ì•½
            history_summary = ""
            if revision_history:
                history_items = []
                for i, h in enumerate(revision_history):
                    history_items.append(f"- ìˆ˜ì • {i+1}íšŒ: {h.get('summary', 'N/A')}")
                history_summary = f"\n**ì´ì „ ìˆ˜ì • ì´ë ¥:**\n{chr(10).join(history_items)}\n"
            
            prompt = f"""ì‚¬ëŒì˜ í”¼ë“œë°±ì„ **ì¶©ì‹¤íˆ ë°˜ì˜**í•˜ì—¬ ì œì•ˆì„œë¥¼ ìˆ˜ì •í•´ì£¼ì„¸ìš”.

**ì›ë˜ ì‘ì—…:** {state['task']}
{history_summary}
**í˜„ì¬ ì œì•ˆì„œ:**
{state.get('agent_proposal', '')}

---

**ğŸ”´ ë°˜ë“œì‹œ ë°˜ì˜í•´ì•¼ í•  í”¼ë“œë°±:**
{human_feedback}

---

**ìˆ˜ì • ê°€ì´ë“œë¼ì¸:**
1. í”¼ë“œë°±ì—ì„œ ì§€ì í•œ ëª¨ë“  ì‚¬í•­ì„ êµ¬ì²´ì ìœ¼ë¡œ ê°œì„ í•˜ì„¸ìš”
2. ìˆ˜ì •ëœ ë¶€ë¶„ì„ ëª…í™•íˆ í‘œì‹œí•˜ì„¸ìš” (ì˜ˆ: "ğŸ”„ ìˆ˜ì •ë¨")
3. ê¸°ì¡´ì˜ ì¥ì ì€ ìœ ì§€í•˜ë©´ì„œ ê°œì„ í•˜ì„¸ìš”
4. í”¼ë“œë°±ì— ì—†ëŠ” ë¶€ë¶„ë„ ì „ë°˜ì ì¸ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•´ ê°œì„ í•˜ì„¸ìš”

**ê°œì„ ëœ ì œì•ˆì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”:**"""
        
        proposal = await self._generate_with_streaming(prompt, "proposal_generator")
        
        logger.info(f"âœ… [Agent] ì œì•ˆ ì™„ë£Œ (ìˆ˜ì • {revision_count}íšŒ)")
        
        # ë©”ì‹œì§€ êµ¬ì„±
        revision_badge = f" (ğŸ”„ {revision_count}ì°¨ ìˆ˜ì •ë³¸)" if revision_count > 0 else ""
        header = f"**[Agent - ì œì•ˆì„œ ìƒì„±{revision_badge}]**"
        
        if revision_count > 0:
            header += f"\n\nğŸ“Œ **ë°˜ì˜ëœ í”¼ë“œë°±:** {human_feedback[:100]}..." if len(human_feedback or '') > 100 else f"\n\nğŸ“Œ **ë°˜ì˜ëœ í”¼ë“œë°±:** {human_feedback}"
        
        return {
            'agent_proposal': proposal,
            'workflow_status': 'awaiting_human_input',
            'awaiting_input': True,  # âœ¨ ì‚¬ëŒ ì…ë ¥ ëŒ€ê¸° ì‹ í˜¸!
            'messages': [AIMessage(content=f"{header}\n\n{proposal}")]
        }
    
    async def human_gate(self, state: HITLState) -> dict:
        """
        Human Gate: ì‹¤ì œ ì‚¬ëŒì˜ ê²°ì •ì„ ì ìš©
        
        âš ï¸ ì´ ë…¸ë“œëŠ” ì™¸ë¶€ì—ì„œ human_decision, human_feedback, revision_countê°€
        stateì— ì£¼ì…ëœ í›„ì— ì‹¤í–‰ë©ë‹ˆë‹¤.
        (revision_count ì¦ê°€ëŠ” service.pyì—ì„œ ì²˜ë¦¬)
        """
        logger.info("ğŸ‘¤ [Human Gate] ì‚¬ëŒì˜ ê²°ì • ì²˜ë¦¬ ì¤‘...")
        
        # service.pyì—ì„œ ì´ë¯¸ ì¦ê°€ëœ revision_count ì‚¬ìš©
        revision_count = state.get('revision_count', 0)
        decision = state.get('human_decision', 'approve')
        feedback = state.get('human_feedback', '')
        revision_history = state.get('revision_history', [])
        max_revisions = state.get('max_revisions', self.max_revisions)
        
        # ê²°ì •ì— ë”°ë¥¸ ìƒíƒœ ë§¤í•‘
        status_map = {
            "approve": "approved",
            "reject": "rejected",
            "revision": "revision_requested"
        }
        
        # ê²°ì • ì´ëª¨ì§€
        decision_emoji = {
            "approve": "âœ…",
            "reject": "â›”",
            "revision": "ğŸŸ¡"
        }
        
        emoji = decision_emoji.get(decision, "â“")
        new_status = status_map.get(decision, 'approved')
        
        # ìµœëŒ€ ìˆ˜ì • íšŸìˆ˜ ì²´í¬
        if decision == "revision" and revision_count >= max_revisions:
            logger.warning(f"âš ï¸ ìµœëŒ€ ìˆ˜ì • íšŸìˆ˜({max_revisions}íšŒ) ë„ë‹¬")
        
        logger.info(f"âœ… [Human Gate] ê²°ì •: {decision.upper()} (ìˆ˜ì • {revision_count}íšŒ)")
        
        # ë©”ì‹œì§€ êµ¬ì„±
        message_content = f"""**[Human Review - ê²€í†  ê²°ê³¼]**

---

**{emoji} ê²°ì •:** {decision.upper()}

**ğŸ“ í”¼ë“œë°±:**
{feedback if feedback else "(í”¼ë“œë°± ì—†ìŒ)"}

---

**ğŸ“Š í†µê³„:**
- í˜„ì¬ ìˆ˜ì • íšŸìˆ˜: {revision_count}íšŒ / ìµœëŒ€ {max_revisions}íšŒ
- ì›Œí¬í”Œë¡œìš° ìƒíƒœ: {new_status}"""

        if decision == "revision" and revision_count >= max_revisions:
            message_content += f"\n\nâš ï¸ **ì£¼ì˜:** ìµœëŒ€ ìˆ˜ì • íšŸìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ê²°ì •ì—ì„œ ìŠ¹ì¸ ë˜ëŠ” ê±°ë¶€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."
        
        return {
            'human_decision': decision,
            'human_feedback': feedback,
            'workflow_status': new_status,
            'awaiting_input': False,
            # revision_countëŠ” service.pyì—ì„œ ì´ë¯¸ ì„¤ì •ë¨, ê·¸ëŒ€ë¡œ ìœ ì§€
            'messages': [AIMessage(content=message_content)]
        }
    
    def should_continue(self, state: HITLState) -> str:
        """ë‹¤ìŒ ë‹¨ê³„ ê²°ì • (3ë‹¨ ë¶„ê¸°)"""
        decision = state.get('human_decision', '')
        revision_count = state.get('revision_count', 0)
        max_revisions = state.get('max_revisions', self.max_revisions)
        
        # ìµœëŒ€ ìˆ˜ì • íšŸìˆ˜ ë„ë‹¬ ì‹œ ê°•ì œ ì¢…ë£Œ
        if revision_count >= max_revisions and decision == "revision":
            logger.info(f"âš ï¸ [ì¢…ë£Œ] ìµœëŒ€ ìˆ˜ì • íšŸìˆ˜({max_revisions}íšŒ) ë„ë‹¬ - ìë™ ìŠ¹ì¸ ì²˜ë¦¬")
            return "finalize"
        
        if decision == "approve":
            logger.info("âœ… [ë¶„ê¸°] ìŠ¹ì¸ â†’ Finalizer")
            return "finalize"
        elif decision == "reject":
            logger.info("â›” [ë¶„ê¸°] ê±°ë¶€ â†’ Finalizer")
            return "finalize"
        elif decision == "revision":
            logger.info(f"ğŸŸ¡ [ë¶„ê¸°] ìˆ˜ì • ìš”ì²­ â†’ Generator (ìˆ˜ì • {revision_count}íšŒ)")
            return "revise"
        else:
            logger.warning(f"â“ [ë¶„ê¸°] ì•Œ ìˆ˜ ì—†ëŠ” ê²°ì •: {decision} â†’ Finalizer")
            return "finalize"
    
    async def finalizer_node(self, state: HITLState) -> dict:
        """Finalizer: ìµœì¢… ê²°ê³¼ ìƒì„±"""
        logger.info("ğŸ¯ [Finalizer] ìµœì¢… ê²°ê³¼ ìƒì„± ì¤‘...")
        
        decision = state.get('human_decision', '')
        revision_count = state.get('revision_count', 0)
        revision_history = state.get('revision_history', [])
        
        # ê²°ì •ì— ë”°ë¥¸ ìƒíƒœ í…ìŠ¤íŠ¸
        if decision == "approve":
            status_emoji = "âœ…"
            status_text = "ìŠ¹ì¸ë¨"
            final_output = state.get('agent_proposal', '')
        elif decision == "reject":
            status_emoji = "â›”"
            status_text = "ê±°ë¶€ë¨"
            final_output = f"ì œì•ˆì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n**ê±°ë¶€ ì‚¬ìœ :**\n{state.get('human_feedback', 'ì‚¬ìœ  ì—†ìŒ')}"
        else:
            # ìµœëŒ€ ìˆ˜ì • íšŸìˆ˜ ë„ë‹¬ë¡œ ì¸í•œ ìë™ ì¢…ë£Œ
            status_emoji = "âš ï¸"
            status_text = "ìë™ ìŠ¹ì¸ (ìµœëŒ€ ìˆ˜ì • íšŸìˆ˜ ë„ë‹¬)"
            final_output = state.get('agent_proposal', '')
        
        # ìˆ˜ì • ì´ë ¥ ìš”ì•½
        history_summary = ""
        if revision_history:
            history_items = []
            for h in revision_history:
                history_items.append(f"- **ìˆ˜ì • {h['iteration']}íšŒ:** {h['summary']}")
            history_summary = f"""
---

**ğŸ“œ ìˆ˜ì • ì´ë ¥:**
{chr(10).join(history_items)}"""
        
        summary = f"""**[HITL ì›Œí¬í”Œë¡œìš° ì™„ë£Œ]**

---

**{status_emoji} ìµœì¢… ìƒíƒœ:** {status_text}
**ğŸ“Š ì´ ìˆ˜ì • íšŸìˆ˜:** {revision_count}íšŒ / {self.max_revisions}íšŒ
{history_summary}

---

**ğŸ“„ ìµœì¢… ì œì•ˆì„œ:**

{final_output}"""
        
        logger.info(f"âœ… [Finalizer] ì™„ë£Œ - {status_text}")
        
        return {
            'workflow_status': 'completed',
            'awaiting_input': False,
            'final_output': final_output,
            'messages': [AIMessage(content=summary)]
        }
    
    def create_graph(self) -> StateGraph:
        """HITL ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„± (ì‹¤ì œ ì‚¬ëŒ ê°œì…)"""
        workflow = StateGraph(HITLState)
        
        # ë…¸ë“œ ì¶”ê°€
        workflow.add_node("proposal_generator", self.proposal_generator)
        workflow.add_node("human_gate", self.human_gate)  # âœ¨ ì‹¤ì œ ì‚¬ëŒ ê²°ì • ì²˜ë¦¬
        workflow.add_node("finalizer", self.finalizer_node)
        
        # ì—£ì§€ ì¶”ê°€
        workflow.set_entry_point("proposal_generator")
        workflow.add_edge("proposal_generator", "human_gate")
        
        # ì¡°ê±´ë¶€ ì—£ì§€: Human ê²°ì •ì— ë”°ë¼ 3ë‹¨ ë¶„ê¸°
        workflow.add_conditional_edges(
            "human_gate",
            self.should_continue,
            {
                "revise": "proposal_generator",  # ğŸŸ¡ ìˆ˜ì • ìš”ì²­ â†’ Generator ì¬í˜¸ì¶œ
                "finalize": "finalizer"  # âœ…â›” ìŠ¹ì¸/ê±°ë¶€ â†’ ì¢…ë£Œ
            }
        )
        
        workflow.add_edge("finalizer", END)
        
        logger.info("âœ… [HITL] ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ - ì‹¤ì œ ì‚¬ëŒ ê°œì… + 3ë‹¨ ë¶„ê¸° (approve/revision/reject)")
        return workflow.compile()


# ============================================================================
# Pattern Registry
# ============================================================================

def get_pattern(pattern_name: str, llm_service, stream_callback: Optional[StreamCallback] = None, **kwargs):
    """íŒ¨í„´ íŒ©í† ë¦¬ - í† í° ìŠ¤íŠ¸ë¦¬ë° ì½œë°± ì§€ì›"""
    patterns = {
        "sequential": SequentialPattern,
        "planner_executor": PlannerExecutorPattern,
        "role_based": RoleBasedPattern,
        "hierarchical": HierarchicalPattern,
        "debate": DebatePattern,
        "swarm": SwarmPattern,
        "reflection": ReflectionPattern,
        "routing": RoutingPattern,
        "hitl": HITLPattern,
    }
    
    pattern_class = patterns.get(pattern_name)
    if not pattern_class:
        raise ValueError(f"Unknown pattern: {pattern_name}. Available: {list(patterns.keys())}")
    
    # íŒ¨í„´ë³„ ì¶”ê°€ ì¸ì ì „ë‹¬ + ìŠ¤íŠ¸ë¦¬ë° ì½œë°±
    if pattern_name == "debate":
        return pattern_class(llm_service, max_rounds=kwargs.get("max_rounds", 3), stream_callback=stream_callback)
    elif pattern_name == "swarm":
        return pattern_class(llm_service, num_agents=kwargs.get("num_agents", 5), stream_callback=stream_callback)
    elif pattern_name == "reflection":
        return pattern_class(
            llm_service, 
            max_iterations=kwargs.get("max_iterations", 3),
            quality_threshold=kwargs.get("quality_threshold", 8.0),
            improvement_threshold=kwargs.get("improvement_threshold", 0.3),
            stream_callback=stream_callback
        )
    elif pattern_name == "hitl":
        return pattern_class(llm_service, max_revisions=kwargs.get("max_revisions", 3), stream_callback=stream_callback)
    else:
        return pattern_class(llm_service, stream_callback=stream_callback)

